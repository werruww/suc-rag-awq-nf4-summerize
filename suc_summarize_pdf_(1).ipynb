{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d5893636041d42e38cff2c846b495e67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18b2b82e33ad4206a72f66dbc447da3f",
              "IPY_MODEL_02a24d062ad341d1a705ae7a666fcdc1",
              "IPY_MODEL_f73c214ccc33469686f7e8e8154d0e67"
            ],
            "layout": "IPY_MODEL_8e6d4595499e4435a924d406783d4666"
          }
        },
        "18b2b82e33ad4206a72f66dbc447da3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2faf985275d14025bc44a1761640f9b8",
            "placeholder": "​",
            "style": "IPY_MODEL_04d9169371974dcb87eb8bc959e63226",
            "value": "Batches: 100%"
          }
        },
        "02a24d062ad341d1a705ae7a666fcdc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce8565f8177341d1b4cba568d8ed3948",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8884dc01daf349e3b6c8820e5cee4e06",
            "value": 1
          }
        },
        "f73c214ccc33469686f7e8e8154d0e67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b59b54a4b8e6469583d3ecfb2156cf30",
            "placeholder": "​",
            "style": "IPY_MODEL_76e26712d0d34a10bea0dc1ae17223a3",
            "value": " 1/1 [00:06&lt;00:00,  6.73s/it]"
          }
        },
        "8e6d4595499e4435a924d406783d4666": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2faf985275d14025bc44a1761640f9b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04d9169371974dcb87eb8bc959e63226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce8565f8177341d1b4cba568d8ed3948": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8884dc01daf349e3b6c8820e5cee4e06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b59b54a4b8e6469583d3ecfb2156cf30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76e26712d0d34a10bea0dc1ae17223a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74fbf52deb8d48e8bb619f219ad465d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18d5797b67cf40e9aae975924b283652",
              "IPY_MODEL_3fcf963dfdc343b3bcf636e4da7e1824",
              "IPY_MODEL_b39125ba300e4d7b87d3514bbd554a36"
            ],
            "layout": "IPY_MODEL_333733d3fb354b73a609ec17587ff3cd"
          }
        },
        "18d5797b67cf40e9aae975924b283652": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e297e84ee1c54a5ebda7640c87fbbb6e",
            "placeholder": "​",
            "style": "IPY_MODEL_8da6e6e29dc64daca48dccbde7f4c677",
            "value": "config.json: 100%"
          }
        },
        "3fcf963dfdc343b3bcf636e4da7e1824": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66637f0bf4f543298f8590d7a934ebf7",
            "max": 1404,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c10aa9116b214bb5b7d2d1e980128359",
            "value": 1404
          }
        },
        "b39125ba300e4d7b87d3514bbd554a36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e747f94059344998b3b3f7cee9963eb",
            "placeholder": "​",
            "style": "IPY_MODEL_eef7680245a14be5b7f5dcce0d12e491",
            "value": " 1.40k/1.40k [00:00&lt;00:00, 70.3kB/s]"
          }
        },
        "333733d3fb354b73a609ec17587ff3cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e297e84ee1c54a5ebda7640c87fbbb6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8da6e6e29dc64daca48dccbde7f4c677": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66637f0bf4f543298f8590d7a934ebf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c10aa9116b214bb5b7d2d1e980128359": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e747f94059344998b3b3f7cee9963eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eef7680245a14be5b7f5dcce0d12e491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "144b855dc59c4cf1aaaa24c4743e8608": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7020a26037a644ab96a3a04e1a4b6896",
              "IPY_MODEL_d3e6319b121e4f34a942acf684db7df0",
              "IPY_MODEL_3592816c25ac409e9a64192661e87c56"
            ],
            "layout": "IPY_MODEL_a064ff491b5149dca1aae163e387be7f"
          }
        },
        "7020a26037a644ab96a3a04e1a4b6896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b89bfbc80ddd4004b179dc08e00e3336",
            "placeholder": "​",
            "style": "IPY_MODEL_ce1526f2185244c5b41d70998fbaba44",
            "value": "model.safetensors: 100%"
          }
        },
        "d3e6319b121e4f34a942acf684db7df0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a0d215867fa4393b2a457cbbebf4cc0",
            "max": 990345061,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_21c3db9317df461e9c18852ab7ff2f70",
            "value": 990345061
          }
        },
        "3592816c25ac409e9a64192661e87c56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d80e69ba6ae5455ebb953712bc8532c5",
            "placeholder": "​",
            "style": "IPY_MODEL_5f2241194ef045ec8b53945cb9005e5a",
            "value": " 990M/990M [00:20&lt;00:00, 94.4MB/s]"
          }
        },
        "a064ff491b5149dca1aae163e387be7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b89bfbc80ddd4004b179dc08e00e3336": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce1526f2185244c5b41d70998fbaba44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a0d215867fa4393b2a457cbbebf4cc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21c3db9317df461e9c18852ab7ff2f70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d80e69ba6ae5455ebb953712bc8532c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f2241194ef045ec8b53945cb9005e5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "891b0105353b45c08b4fd0564dffba08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_452c3541a2c1413993f08910d1de6441",
              "IPY_MODEL_509f62d9f17a48a8b3678ab43b10464a",
              "IPY_MODEL_2092ab19bef149cabe774efa74f5b40d"
            ],
            "layout": "IPY_MODEL_e460e93865b14de9a3f3fd848d8d2b43"
          }
        },
        "452c3541a2c1413993f08910d1de6441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bbb8c942bdb46d7ad01a244f2cc5cb0",
            "placeholder": "​",
            "style": "IPY_MODEL_631333d858b2419ba74a7ce77fec5f9d",
            "value": "generation_config.json: 100%"
          }
        },
        "509f62d9f17a48a8b3678ab43b10464a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf988e66c80649bda5cadece76e21b29",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e5016a029c3407b9ff75c7fae856763",
            "value": 147
          }
        },
        "2092ab19bef149cabe774efa74f5b40d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4e1aebe771f42e1a523f5d1a978a078",
            "placeholder": "​",
            "style": "IPY_MODEL_d163c859590b46fcab914b32b3b55a0b",
            "value": " 147/147 [00:00&lt;00:00, 2.72kB/s]"
          }
        },
        "e460e93865b14de9a3f3fd848d8d2b43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bbb8c942bdb46d7ad01a244f2cc5cb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "631333d858b2419ba74a7ce77fec5f9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf988e66c80649bda5cadece76e21b29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e5016a029c3407b9ff75c7fae856763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b4e1aebe771f42e1a523f5d1a978a078": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d163c859590b46fcab914b32b3b55a0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad2c8fce6eba46199bb67045b1b2551c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ebda8ba8df2c4affbcb67b3739037118",
              "IPY_MODEL_b7af8d3da2b94ad4a374035ad6603dae",
              "IPY_MODEL_f38cfcc515fd4854b5a11482a8019c7c"
            ],
            "layout": "IPY_MODEL_66179cf6cffc4bd3b9da98f619c77fa9"
          }
        },
        "ebda8ba8df2c4affbcb67b3739037118": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9c6aaca1ece4842adf23e1da46cec77",
            "placeholder": "​",
            "style": "IPY_MODEL_ab3c108b89b84576b76760574a3de1e7",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "b7af8d3da2b94ad4a374035ad6603dae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c2f58cae7cf46eb90a8533636b130eb",
            "max": 2537,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6b9c83d730d4d9293e73ff75ff4fd60",
            "value": 2537
          }
        },
        "f38cfcc515fd4854b5a11482a8019c7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3583674dcdc4a31a42349109454c179",
            "placeholder": "​",
            "style": "IPY_MODEL_95803c0b1b9e40fca55d885aac91c2a7",
            "value": " 2.54k/2.54k [00:00&lt;00:00, 37.4kB/s]"
          }
        },
        "66179cf6cffc4bd3b9da98f619c77fa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9c6aaca1ece4842adf23e1da46cec77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab3c108b89b84576b76760574a3de1e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c2f58cae7cf46eb90a8533636b130eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6b9c83d730d4d9293e73ff75ff4fd60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a3583674dcdc4a31a42349109454c179": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95803c0b1b9e40fca55d885aac91c2a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2863e64a6f84bf3be1bc93972a62a93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_463178b5298348058b5137f520d7765d",
              "IPY_MODEL_1c290f5702494c80baa9f36b3d54d01e",
              "IPY_MODEL_826eda85b0184c3086a53f8745f3cdb1"
            ],
            "layout": "IPY_MODEL_443fe9d9768847dc9178b760612652b8"
          }
        },
        "463178b5298348058b5137f520d7765d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b6dcf211a1341bd86144e84b0f128a4",
            "placeholder": "​",
            "style": "IPY_MODEL_fb417c50b9624886a55df5e25b89c5f0",
            "value": "spiece.model: 100%"
          }
        },
        "1c290f5702494c80baa9f36b3d54d01e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5d43b450746402eaa72ecabda915ed5",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82443007642a4f858ac001f672c872b9",
            "value": 791656
          }
        },
        "826eda85b0184c3086a53f8745f3cdb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ae3ce2459f24157a8ee0fce54910ba4",
            "placeholder": "​",
            "style": "IPY_MODEL_69b11d8b139a4919a27442976d7870ea",
            "value": " 792k/792k [00:01&lt;00:00, 589kB/s]"
          }
        },
        "443fe9d9768847dc9178b760612652b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b6dcf211a1341bd86144e84b0f128a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb417c50b9624886a55df5e25b89c5f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5d43b450746402eaa72ecabda915ed5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82443007642a4f858ac001f672c872b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ae3ce2459f24157a8ee0fce54910ba4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69b11d8b139a4919a27442976d7870ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ee68c92cb6d4b6fad2dbfa0c9565e77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b357b71c7284f9ead5ee308bdf8d373",
              "IPY_MODEL_c85bfeb4724a4eac8c9a50df1d340314",
              "IPY_MODEL_57bb6e5005c84a6a9bf12de4519a3cd5"
            ],
            "layout": "IPY_MODEL_a8b4f54425024633b08c0fbbb91a2af1"
          }
        },
        "6b357b71c7284f9ead5ee308bdf8d373": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a74cd52c207146979e76740e3eebfe3f",
            "placeholder": "​",
            "style": "IPY_MODEL_f345311c047346e8b7d1ff0a433135c0",
            "value": "tokenizer.json: 100%"
          }
        },
        "c85bfeb4724a4eac8c9a50df1d340314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbdd7a52adbd41338ce1aae4baca4be7",
            "max": 2424064,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_018e4acd828a4ee19bdd6a4dda9b826a",
            "value": 2424064
          }
        },
        "57bb6e5005c84a6a9bf12de4519a3cd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e72d390fccd427f9283f7ea1c5fb232",
            "placeholder": "​",
            "style": "IPY_MODEL_fa2dc9a5b50244d6b8edcbab5b76d2ba",
            "value": " 2.42M/2.42M [00:00&lt;00:00, 2.72MB/s]"
          }
        },
        "a8b4f54425024633b08c0fbbb91a2af1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a74cd52c207146979e76740e3eebfe3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f345311c047346e8b7d1ff0a433135c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbdd7a52adbd41338ce1aae4baca4be7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "018e4acd828a4ee19bdd6a4dda9b826a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e72d390fccd427f9283f7ea1c5fb232": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa2dc9a5b50244d6b8edcbab5b76d2ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a5a9e9bd96e4444b4aab723c13720b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a9e87afbcd0421b94d8cbc560a3dc3d",
              "IPY_MODEL_e7e3117a1c7840be810ba722f38870c1",
              "IPY_MODEL_4c2bc905325b4a3fb21b6175340332cb"
            ],
            "layout": "IPY_MODEL_9d47da6c1cc84a1a9cf60b82698ed880"
          }
        },
        "5a9e87afbcd0421b94d8cbc560a3dc3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e72f083ff52c42bf96d1f02b8823575a",
            "placeholder": "​",
            "style": "IPY_MODEL_e1005d827f504caeb54c4925a15946db",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "e7e3117a1c7840be810ba722f38870c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44b9e0f2aba24b69ab0a1f5bcff8832c",
            "max": 2201,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa4bc20de8fb478db730ecc0a849d769",
            "value": 2201
          }
        },
        "4c2bc905325b4a3fb21b6175340332cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_756881b2cbda468bbba4c85fa96ac7cb",
            "placeholder": "​",
            "style": "IPY_MODEL_137a067db4e8453aa4bbecafcc317408",
            "value": " 2.20k/2.20k [00:00&lt;00:00, 28.6kB/s]"
          }
        },
        "9d47da6c1cc84a1a9cf60b82698ed880": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e72f083ff52c42bf96d1f02b8823575a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1005d827f504caeb54c4925a15946db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44b9e0f2aba24b69ab0a1f5bcff8832c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa4bc20de8fb478db730ecc0a849d769": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "756881b2cbda468bbba4c85fa96ac7cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "137a067db4e8453aa4bbecafcc317408": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abaca42bd62f4114935fd710c8574e0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81939e0f070b4b5cb7ad7cfa3c6f6073",
              "IPY_MODEL_500a0020c451496b85c51d5910a5a9f5",
              "IPY_MODEL_a9f58ae55c264cbd933b8c38cffad3cf"
            ],
            "layout": "IPY_MODEL_e7be61c97ebe45118ef38b234ff72558"
          }
        },
        "81939e0f070b4b5cb7ad7cfa3c6f6073": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcbaf01370d04df5af28cc4d17c7e3ed",
            "placeholder": "​",
            "style": "IPY_MODEL_b13fa867c77c440997730be872ffd6c2",
            "value": "config.json: 100%"
          }
        },
        "500a0020c451496b85c51d5910a5a9f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9baff2100675421db14900ea61e21b56",
            "max": 662,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7eb0507a8900484893c1bb4263fdf5f6",
            "value": 662
          }
        },
        "a9f58ae55c264cbd933b8c38cffad3cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b6145ab1a18409692d9cab92a5c11e8",
            "placeholder": "​",
            "style": "IPY_MODEL_3afaf259ed1248fa96cf44e55101a200",
            "value": " 662/662 [00:00&lt;00:00, 14.0kB/s]"
          }
        },
        "e7be61c97ebe45118ef38b234ff72558": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcbaf01370d04df5af28cc4d17c7e3ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b13fa867c77c440997730be872ffd6c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9baff2100675421db14900ea61e21b56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7eb0507a8900484893c1bb4263fdf5f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b6145ab1a18409692d9cab92a5c11e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3afaf259ed1248fa96cf44e55101a200": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78b88e69762244f788ee522ab2600949": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75115f3575b242cba6dca62bbcd85eb3",
              "IPY_MODEL_a4847b4fb0b4492e83d92680bc54046d",
              "IPY_MODEL_160abfb993044fb39d199d7b488ab065"
            ],
            "layout": "IPY_MODEL_65d6a960c5d442c5a5f1f513062e62af"
          }
        },
        "75115f3575b242cba6dca62bbcd85eb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a37c8a7238d6490f97ded11d531c985d",
            "placeholder": "​",
            "style": "IPY_MODEL_2c69367e70d54c71b5c74c39527c48b8",
            "value": "model.safetensors: 100%"
          }
        },
        "a4847b4fb0b4492e83d92680bc54046d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f922bb1fb2394efd90099ad0119c1523",
            "max": 3132668804,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de37009cd8ed4575bd803c9922e25c82",
            "value": 3132668804
          }
        },
        "160abfb993044fb39d199d7b488ab065": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8b2de49e73141e190740ebec645c296",
            "placeholder": "​",
            "style": "IPY_MODEL_ac8cabe024034acebf3515696533748a",
            "value": " 3.13G/3.13G [01:23&lt;00:00, 78.6MB/s]"
          }
        },
        "65d6a960c5d442c5a5f1f513062e62af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a37c8a7238d6490f97ded11d531c985d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c69367e70d54c71b5c74c39527c48b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f922bb1fb2394efd90099ad0119c1523": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de37009cd8ed4575bd803c9922e25c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8b2de49e73141e190740ebec645c296": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac8cabe024034acebf3515696533748a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65ed2ae6d16649d48dc074024bf6c76e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00a82488333e436792c06e71ed2e87d9",
              "IPY_MODEL_dc6c54f4b88c44b289ec7adf083a47f1",
              "IPY_MODEL_1d171c3ed52947e6b2f11a7e7062e0df"
            ],
            "layout": "IPY_MODEL_00d6af223a614e7ea4ec4b08d5eeca75"
          }
        },
        "00a82488333e436792c06e71ed2e87d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3612410c8de418791f89a7d04a7ba43",
            "placeholder": "​",
            "style": "IPY_MODEL_3daeccfc2de942be8173613f41d22085",
            "value": "generation_config.json: 100%"
          }
        },
        "dc6c54f4b88c44b289ec7adf083a47f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35ee74a1519444d890980eb0279d517e",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_763c785ab74d4fa7b402d5861dcb7117",
            "value": 147
          }
        },
        "1d171c3ed52947e6b2f11a7e7062e0df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_526ff1af41a24cf9b68be19e20ced909",
            "placeholder": "​",
            "style": "IPY_MODEL_7fa82453f3614fcd9740b3920e9e54d0",
            "value": " 147/147 [00:00&lt;00:00, 9.62kB/s]"
          }
        },
        "00d6af223a614e7ea4ec4b08d5eeca75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3612410c8de418791f89a7d04a7ba43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3daeccfc2de942be8173613f41d22085": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35ee74a1519444d890980eb0279d517e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "763c785ab74d4fa7b402d5861dcb7117": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "526ff1af41a24cf9b68be19e20ced909": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fa82453f3614fcd9740b3920e9e54d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "335c909cc5df43738a7cb009bfed2925": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_61f47ef062bd41a59d68345bb33439f6",
              "IPY_MODEL_e8a3015d075047439b9ef8f7a59c6942",
              "IPY_MODEL_b6d50663a4304328a508f4cd01593c99"
            ],
            "layout": "IPY_MODEL_dfc6882182a54ebaa03dc5b81189a26a"
          }
        },
        "61f47ef062bd41a59d68345bb33439f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91d64ee73a334ed59cb1588378d83bf8",
            "placeholder": "​",
            "style": "IPY_MODEL_f9ad51ff89a44d36b89c6b70856b9812",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "e8a3015d075047439b9ef8f7a59c6942": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebe55e59f25c4af992bec96977cb5a79",
            "max": 2539,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d12bea0b34d149468389580049ee4c14",
            "value": 2539
          }
        },
        "b6d50663a4304328a508f4cd01593c99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbfc2adb002b4c1a967669325c20c062",
            "placeholder": "​",
            "style": "IPY_MODEL_47daaf7e3aec4ebc854bf37970729f32",
            "value": " 2.54k/2.54k [00:00&lt;00:00, 129kB/s]"
          }
        },
        "dfc6882182a54ebaa03dc5b81189a26a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91d64ee73a334ed59cb1588378d83bf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9ad51ff89a44d36b89c6b70856b9812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebe55e59f25c4af992bec96977cb5a79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d12bea0b34d149468389580049ee4c14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dbfc2adb002b4c1a967669325c20c062": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47daaf7e3aec4ebc854bf37970729f32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b35a198e20bc42f1bb82d9f2f4bd5a83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4dc4220ab8e54f46acb9285da3035df1",
              "IPY_MODEL_9fd03bc912ae4b20ad4a606379096cc0",
              "IPY_MODEL_0569fa12d7cb48ec9c7a65afaae60243"
            ],
            "layout": "IPY_MODEL_048b5e352b01491faed9341c3f9041b6"
          }
        },
        "4dc4220ab8e54f46acb9285da3035df1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e27a3faafceb4b8abbec42de369b2afd",
            "placeholder": "​",
            "style": "IPY_MODEL_52c9e1f2a0fc4d058601391f22dcfc22",
            "value": "spiece.model: 100%"
          }
        },
        "9fd03bc912ae4b20ad4a606379096cc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13c096082fa54472980f8f6df0f4e7b8",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc2a780fb3f84f20a96b41d0071d1363",
            "value": 791656
          }
        },
        "0569fa12d7cb48ec9c7a65afaae60243": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe9c57976ac94549b7f3c1fe5f7c05d7",
            "placeholder": "​",
            "style": "IPY_MODEL_39369cb73be5472b8c1c31d45e29a142",
            "value": " 792k/792k [00:01&lt;00:00, 172kB/s]"
          }
        },
        "048b5e352b01491faed9341c3f9041b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e27a3faafceb4b8abbec42de369b2afd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52c9e1f2a0fc4d058601391f22dcfc22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13c096082fa54472980f8f6df0f4e7b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc2a780fb3f84f20a96b41d0071d1363": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe9c57976ac94549b7f3c1fe5f7c05d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39369cb73be5472b8c1c31d45e29a142": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "211ce06e26b949628def5aaa808ebde0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e53ff878c4245c4aaa985517620fad4",
              "IPY_MODEL_efd0e3b9adc6443f9e661c1c616e6cad",
              "IPY_MODEL_8ca0a90240494d3492917ddecc39b4d1"
            ],
            "layout": "IPY_MODEL_b62aae3ddacd4b2cb0733b34bf62197c"
          }
        },
        "7e53ff878c4245c4aaa985517620fad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e610842601f04811b8ce75ebdd5dcfe6",
            "placeholder": "​",
            "style": "IPY_MODEL_65e73038abf940e78ec7d4e9672eaed4",
            "value": "tokenizer.json: 100%"
          }
        },
        "efd0e3b9adc6443f9e661c1c616e6cad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a38372a0c86749d9ab438e80c546fd9e",
            "max": 2424064,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c56dd06a0a23418bad7033349cc1fe84",
            "value": 2424064
          }
        },
        "8ca0a90240494d3492917ddecc39b4d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfeffa7413e649f58c178e20ce1a75dd",
            "placeholder": "​",
            "style": "IPY_MODEL_f2d8a73a79fc42e1940e8cdb4d3aa929",
            "value": " 2.42M/2.42M [00:00&lt;00:00, 3.35MB/s]"
          }
        },
        "b62aae3ddacd4b2cb0733b34bf62197c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e610842601f04811b8ce75ebdd5dcfe6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65e73038abf940e78ec7d4e9672eaed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a38372a0c86749d9ab438e80c546fd9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c56dd06a0a23418bad7033349cc1fe84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cfeffa7413e649f58c178e20ce1a75dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2d8a73a79fc42e1940e8cdb4d3aa929": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cf46a88dc9544759366c7cd325fdf51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be505c85f2fd4345ac5501ce4daf1269",
              "IPY_MODEL_c95f36016bf1454db856de5fa43ec8b8",
              "IPY_MODEL_75a7115ce20c43ee9774849d2c3c28ab"
            ],
            "layout": "IPY_MODEL_6a1a54abdd004a39b1f3d6f966fe355f"
          }
        },
        "be505c85f2fd4345ac5501ce4daf1269": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00529e75b7074648b5cfdabc1500a15f",
            "placeholder": "​",
            "style": "IPY_MODEL_e0587be7ce01406c8f4aa53257cf0af0",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "c95f36016bf1454db856de5fa43ec8b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_991954b00b6f4fd3a092bb02650f99d5",
            "max": 2201,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80c1fdf61df1489dbdc1240b0be64b73",
            "value": 2201
          }
        },
        "75a7115ce20c43ee9774849d2c3c28ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f826ca15299f468494a93efcfcda5874",
            "placeholder": "​",
            "style": "IPY_MODEL_e73c76c3c28a46f69764ef4f14d027f4",
            "value": " 2.20k/2.20k [00:00&lt;00:00, 143kB/s]"
          }
        },
        "6a1a54abdd004a39b1f3d6f966fe355f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00529e75b7074648b5cfdabc1500a15f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0587be7ce01406c8f4aa53257cf0af0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "991954b00b6f4fd3a092bb02650f99d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80c1fdf61df1489dbdc1240b0be64b73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f826ca15299f468494a93efcfcda5874": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e73c76c3c28a46f69764ef4f14d027f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9dJxWxEcbHK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mS2cZYamfh7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit faiss-cpu langchain sentence-transformers huggingface-hub transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqi6WVOufh-x",
        "outputId": "3bd61e53-b756-4808-c55d-31b1c071d2d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.45.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (0.32.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.0)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m907.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.63)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.44)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.5)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (2025.3.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (1.1.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.41.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Downloading streamlit-1.45.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, faiss-cpu, pydeck, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, streamlit\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed faiss-cpu-1.11.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pydeck-0.9.1 streamlit-1.45.1 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py\n",
        "import streamlit as st\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "st.title(\"📚 RAG بدون OpenAI - نموذج محلي\")\n",
        "\n",
        "# 1. تحميل الملف\n",
        "uploaded_file = st.file_uploader(\"ارفع ملف PDF\", type=\"pdf\")\n",
        "\n",
        "if uploaded_file:\n",
        "    st.success(\"تم رفع الملف بنجاح!\")\n",
        "\n",
        "    # 2. استخراج النصوص وتجزئتها\n",
        "    loader = PyPDFLoader(uploaded_file.name)\n",
        "    documents = loader.load()\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "\n",
        "    # 3. التضمين Embeddings\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    db = FAISS.from_documents(texts, embeddings)\n",
        "\n",
        "    # 4. استعلام المستخدم\n",
        "    query = st.text_input(\"ما سؤالك حول هذا الكتاب؟\")\n",
        "\n",
        "    if query:\n",
        "        # استرجاع السياق\n",
        "        docs = db.similarity_search(query, k=3)\n",
        "        context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
        "\n",
        "        # 5. النموذج المحلي\n",
        "        model_name = \"OpenGVLab/InternVL3-1B-Instruct\"\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name,\n",
        "            trust_remote_code=True,\n",
        "            torch_dtype=torch.float32,\n",
        "            device_map=\"auto\"\n",
        "        )\n",
        "\n",
        "        prompt = f\"\"\"أجب على السؤال بناءً على النص التالي:\\n\\n{context}\\n\\nالسؤال: {query}\\nالإجابة:\"\"\"\n",
        "\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "        output = model.generate(**inputs, max_new_tokens=200)\n",
        "        answer = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "        st.markdown(\"### ✅ الإجابة:\")\n",
        "        st.write(answer.split(\"الإجابة:\")[-1].strip())\n"
      ],
      "metadata": {
        "id": "JztZeGTvfv4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jPFNfNfggE4",
        "outputId": "0cf4f2c1-ad08-4b2d-b500-1913fd382d94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.11-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.11-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import threading\n",
        "import time\n",
        "\n",
        "ngrok_token = \"XXXX\"\n",
        "ngrok.set_auth_token(ngrok_token)\n",
        "\n",
        "# Start ngrok in a separate thread to avoid blocking\n",
        "def start_ngrok():\n",
        "    public_url = ngrok.connect(8501).public_url\n",
        "    print(f\"🚀 Ngrok Tunnel Open: {public_url}\")\n",
        "\n",
        "ngrok_thread = threading.Thread(target=start_ngrok)\n",
        "ngrok_thread.start()\n",
        "\n",
        "# Wait for ngrok to start (optional)\n",
        "time.sleep(5)\n",
        "\n",
        "# Execute your node.js script\n",
        "!streamlit run app.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtHDU7qGgQm5",
        "outputId": "6e4df7eb-f7e0-4d2d-80d4-2d74a9954714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:pyngrok.process.ngrok:t=2025-06-12T18:58:44+0000 lvl=eror msg=\"failed to reconnect session\" obj=tunnels.session err=\"authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2025-06-12T18:58:44+0000 lvl=eror msg=\"session closing\" obj=tunnels.session err=\"authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2025-06-12T18:58:44+0000 lvl=eror msg=\"terminating with error\" obj=app err=\"authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n\"\n",
            "CRITICAL:pyngrok.process.ngrok:t=2025-06-12T18:58:44+0000 lvl=crit msg=\"command failed\" err=\"authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-06-12T18:58:44+0000 lvl=warn msg=\"failed to check for update\" obj=updater err=\"Post \\\"https://update.equinox.io/check\\\": context canceled\"\n",
            "Exception in thread Thread-9 (start_ngrok):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-4-3989434657>\", line 10, in start_ngrok\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\", line 385, in connect\n",
            "    api_url = get_ngrok_process(pyngrok_config).api_url\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\", line 203, in get_ngrok_process\n",
            "    return process.get_process(pyngrok_config)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyngrok/process.py\", line 271, in get_process\n",
            "    return _start_process(pyngrok_config)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyngrok/process.py\", line 447, in _start_process\n",
            "    raise PyngrokNgrokError(f\"The ngrok process errored on start: {ngrok_process.startup_error}.\",\n",
            "pyngrok.exception.PyngrokNgrokError: The ngrok process errored on start: authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.187.155.18:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py --server.port 7860"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiQPDkYxg7Fx",
        "outputId": "735db20f-7d69-4f53-9411-d3258c29d5b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:7860\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:7860\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.187.155.18:7860\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# عرض تطبيق Streamlit داخل Colab\n",
        "import threading\n",
        "import streamlit.web.bootstrap\n",
        "from streamlit.web.server import Server\n",
        "from streamlit.runtime.scriptrunner import add_script_run_ctx\n",
        "\n",
        "def run():\n",
        "    Server.get_current()._is_running = False\n",
        "    streamlit.web.bootstrap.run('/content/app.py', '', [])\n",
        "\n",
        "t = threading.Thread(target=run)\n",
        "add_script_run_ctx(t)\n",
        "t.start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzoVhRNQg7uU",
        "outputId": "ed1bab02-dbdb-4a47-deb0-8b66885cca9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-12 19:01:19.641 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "Exception in thread Thread-10 (run):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-6-4252555953>\", line 8, in run\n",
            "AttributeError: type object 'Server' has no attribute 'get_current'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install localtunnel\n",
        "!streamlit run app.py\n",
        "!lt --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJIA_tOHhKAY",
        "outputId": "db27449f-b621-4343-ee7b-f9dbb74a81b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement localtunnel (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for localtunnel\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.187.155.18:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/streamlit\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1442, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1363, in main\n",
            "    rv = self.invoke(ctx)\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1830, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1226, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 794, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/cli.py\", line 240, in main_run\n",
            "    _main_run(target, args, flag_options=kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/cli.py\", line 276, in _main_run\n",
            "    bootstrap.run(file, is_hello, args, flag_options)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 355, in run\n",
            "    asyncio.run(main())\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 190, in run\n",
            "    return runner.run(main)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
            "    return self._loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 641, in run_until_complete\n",
            "    self.run_forever()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1898, in _run_once\n",
            "    event_list = self._selector.select(timeout)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/selectors.py\", line 468, in select\n",
            "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 44, in signal_handler\n",
            "    server.stop()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/server/server.py\", line 468, in stop\n",
            "    cli_util.print_to_cli(\"  Stopping...\", fg=\"blue\")\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/cli_util.py\", line 34, in print_to_cli\n",
            "    click.secho(message, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/termui.py\", line 684, in secho\n",
            "    return echo(message, file=file, nl=nl, err=err, color=color)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/utils.py\", line 321, in echo\n",
            "    file.write(out)  # type: ignore\n",
            "    ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 44, in signal_handler\n",
            "    server.stop()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/server/server.py\", line 468, in stop\n",
            "    cli_util.print_to_cli(\"  Stopping...\", fg=\"blue\")\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/cli_util.py\", line 34, in print_to_cli\n",
            "    click.secho(message, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/termui.py\", line 684, in secho\n",
            "    return echo(message, file=file, nl=nl, err=err, color=color)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/utils.py\", line 321, in echo\n",
            "    file.write(out)  # type: ignore\n",
            "    ^^^^^^^^^^^^^^^\n",
            "RuntimeError: reentrant call inside <_io.BufferedWriter name='<stdout>'>\n",
            "/bin/bash: line 1: lt: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit localtunnel --quiet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlusGE--hTFZ",
        "outputId": "9f0b03f8-8908-4340-ea3d-dcbed53e99c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement localtunnel (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for localtunnel\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import threading\n",
        "\n",
        "def run_streamlit():\n",
        "    os.system('streamlit run app.py --server.port 8501')\n",
        "\n",
        "threading.Thread(target=run_streamlit).start()\n",
        "\n",
        "# انتظر قليلًا حتى يفتح السيرفر\n",
        "time.sleep(5)\n",
        "\n",
        "# افتح نفق خارجي بـ localtunnel\n",
        "!lt --port 8501\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ku78W2g-h15p",
        "outputId": "cffd0269-5fd5-4780-b095-06c4d7478b15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: lt: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import threading\n",
        "import os\n",
        "\n",
        "# فتح النفق أولاً (بدون توثيق حساب)\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"📨 رابط الواجهة العامة: {public_url}\")\n",
        "\n",
        "# تشغيل Streamlit في الخلفية\n",
        "def run():\n",
        "    os.system(\"streamlit run app.py --server.port 8501\")\n",
        "\n",
        "thread = threading.Thread(target=run)\n",
        "thread.start()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePSDT-cch2MJ",
        "outputId": "f4eeb26a-8689-4fe8-ca42-2cc8c21c430b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📨 رابط الواجهة العامة: NgrokTunnel: \"https://b255-35-187-155-18.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0W9bOs_idDC",
        "outputId": "38144aff-7897-41ef-929e-2c757d94e786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.25-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.65 (from langchain-community)\n",
            "  Downloading langchain_core-0.3.65-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.25)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.44)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (2.11.5)\n",
            "Collecting langsmith<0.4,>=0.1.125 (from langchain-community)\n",
            "  Downloading langsmith-0.3.45-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain-community) (4.14.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.65->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.25-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain_core-0.3.65-py3-none-any.whl (438 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.1/438.1 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.3.45-py3-none-any.whl (363 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.0/363.0 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, langsmith, dataclasses-json, langchain-core, langchain-community\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.3.44\n",
            "    Uninstalling langsmith-0.3.44:\n",
            "      Successfully uninstalled langsmith-0.3.44\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.63\n",
            "    Uninstalling langchain-core-0.3.63:\n",
            "      Successfully uninstalled langchain-core-0.3.63\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.25 langchain-core-0.3.65 langsmith-0.3.45 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.9.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit langchain langchain-community faiss-cpu sentence-transformers\n",
        "!streamlit run app.py & npx localtunnel --port 8501\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Vf-9mLjh-0h",
        "outputId": "6ce52b3b-04b9-4a35-9169-145d82287794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.45.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.65)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.45)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.5)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.52.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.32.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.41.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8502\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8502\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.187.155.18:8502\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\u001b[1G\u001b[0JNeed to install the following packages:\n",
            "localtunnel@2.0.2\n",
            "Ok to proceed? (y) \u001b[20Gy\n",
            "\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0Kyour url is: https://little-rings-shine.loca.lt\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsPq3psUkWU5",
        "outputId": "a5dee48b-b873-4fb6-fd3c-5765bfe7ff88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-5.6.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Downloading pypdf-5.6.0-py3-none-any.whl (304 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/304.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/304.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.2/304.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"XXXX\"\n"
      ],
      "metadata": {
        "id": "3e_9YbSLk9oL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok, conf\n",
        "\n",
        "# إعداد التوكن هنا\n",
        "conf.get_default().auth_token = \"XXXX\"\n"
      ],
      "metadata": {
        "id": "jtTG0hqGkGWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# افتح نفق ngrok على البورت 8501\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"🔗 رابط الوصول:\", public_url)\n",
        "\n",
        "# شغل Streamlit (يفضل أن يكون app.py موجودًا)\n",
        "!streamlit run app.py &> /dev/null &\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nIaAKJWkMGB",
        "outputId": "1ee19b2b-3982-4d32-f85c-4d8f10880be1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔗 رابط الوصول: NgrokTunnel: \"https://beb6-35-187-155-18.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 📄 app.py\n",
        "import streamlit as st\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "# ↓ استخدام transformers مباشرة\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "\n",
        "# إعداد واجهة Streamlit\n",
        "st.set_page_config(page_title=\"سؤال وجواب على ملفات PDF\", layout=\"centered\")\n",
        "st.title(\"🤖📄 اسأل أي شيء عن ملف PDF\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"📤 ارفع ملف PDF\", type=\"pdf\")\n",
        "\n",
        "if uploaded_file:\n",
        "    # حفظ الملف مؤقتاً\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as tmp_file:\n",
        "        tmp_file.write(uploaded_file.read())\n",
        "        tmp_file_path = tmp_file.name\n",
        "\n",
        "    # تحميل الملف باستخدام LangChain\n",
        "    with st.spinner(\"📚 جاري تحميل الملف...\"):\n",
        "        loader = PyPDFLoader(tmp_file_path)\n",
        "        documents = loader.load()\n",
        "\n",
        "        # تقسيم النص\n",
        "        splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "        chunks = splitter.split_documents(documents)\n",
        "\n",
        "        # استخراج Embeddings\n",
        "        embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "        db = FAISS.from_documents(chunks, embeddings)\n",
        "\n",
        "        retriever = db.as_retriever()\n",
        "\n",
        "        # تحميل نموذج flan-t5-base محليًا بدون API\n",
        "        model_name = \"google/flan-t5-base\"\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "        pipe = pipeline(\n",
        "            \"text2text-generation\",\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            max_new_tokens=300,\n",
        "            temperature=0.2\n",
        "        )\n",
        "\n",
        "        llm = HuggingFacePipeline(pipeline=pipe)\n",
        "\n",
        "        qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
        "\n",
        "        st.success(\"✅ تم تجهيز الملف! يمكنك الآن طرح الأسئلة.\")\n",
        "\n",
        "    # واجهة لطرح الأسئلة\n",
        "    question = st.text_input(\"❓ اكتب سؤالك هنا\")\n",
        "\n",
        "    if question:\n",
        "        with st.spinner(\"🤔 جاري التفكير...\"):\n",
        "            result = qa_chain.run(question)\n",
        "            st.markdown(\"### ✅ الإجابة:\")\n",
        "            st.write(result)\n",
        "\n",
        "    # حذف الملف المؤقت بعد الاستخدام\n",
        "    os.unlink(tmp_file_path)\n"
      ],
      "metadata": {
        "id": "sfb_lDxtkMjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpqn0Ufyl5Qb",
        "outputId": "7dd689f6-99b7-414a-8c46-44c69ed456c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8504\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8504\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.187.155.18:8504\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0Kyour url is: https://afraid-seals-post.loca.lt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-06-12T19:22:22+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8501-3cf11f11-22e0-4f1c-9a5c-3194fb0107c4 acceptErr=\"failed to accept connection: Listener closed\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-06-12T19:22:22+0000 lvl=warn msg=\"Error restarting forwarder\" name=http-8501-3cf11f11-22e0-4f1c-9a5c-3194fb0107c4 err=\"failed to start tunnel: session closed\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-06-12T19:22:22+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8501-800f974d-eda5-401f-ba1a-6d614a1c584c acceptErr=\"failed to accept connection: Listener closed\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-06-12T19:22:22+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8501-080f98b7-dab2-4361-9abc-a59bc6394b9a acceptErr=\"failed to accept connection: Listener closed\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trust_remote_code=True"
      ],
      "metadata": {
        "id": "5YbHQsBFmBx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login --token XXXX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYgTa4c_n0jb",
        "outputId": "eebc817f-9238-4952-e43c-96a07218ab8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "The token `read` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `read`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "شغال\n",
        "\n",
        "/content/app.py\n",
        "\n",
        "\n",
        "\n",
        "# 📄 app.py\n",
        "import streamlit as st\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "# ↓ استخدام transformers مباشرة\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "\n",
        "# إعداد واجهة Streamlit\n",
        "st.set_page_config(page_title=\"سؤال وجواب على ملفات PDF\", layout=\"centered\")\n",
        "st.title(\"🤖📄 اسأل أي شيء عن ملف PDF\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"📤 ارفع ملف PDF\", type=\"pdf\")\n",
        "\n",
        "if uploaded_file:\n",
        "    # حفظ الملف مؤقتاً\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as tmp_file:\n",
        "        tmp_file.write(uploaded_file.read())\n",
        "        tmp_file_path = tmp_file.name\n",
        "\n",
        "    # تحميل الملف باستخدام LangChain\n",
        "    with st.spinner(\"📚 جاري تحميل الملف...\"):\n",
        "        loader = PyPDFLoader(tmp_file_path)\n",
        "        documents = loader.load()\n",
        "\n",
        "        # تقسيم النص\n",
        "        splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "        chunks = splitter.split_documents(documents)\n",
        "\n",
        "        # استخراج Embeddings\n",
        "        embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "        db = FAISS.from_documents(chunks, embeddings)\n",
        "\n",
        "        retriever = db.as_retriever()\n",
        "\n",
        "        # تحميل نموذج flan-t5-base محليًا بدون API\n",
        "        from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "        model_name = \"google/gemma-3-1b-it\"\n",
        "\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "        model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
        "        pipe = pipeline(\n",
        "            \"text2text-generation\",\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            max_new_tokens=300,\n",
        "            temperature=0.2\n",
        "        )\n",
        "\n",
        "        llm = HuggingFacePipeline(pipeline=pipe)\n",
        "\n",
        "        qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
        "\n",
        "        st.success(\"✅ تم تجهيز الملف! يمكنك الآن طرح الأسئلة.\")\n",
        "\n",
        "    # واجهة لطرح الأسئلة\n",
        "    question = st.text_input(\"❓ اكتب سؤالك هنا\")\n",
        "\n",
        "    if question:\n",
        "        with st.spinner(\"🤔 جاري التفكير...\"):\n",
        "            result = qa_chain.run(question)\n",
        "            st.markdown(\"### ✅ الإجابة:\")\n",
        "            st.write(result)\n",
        "\n",
        "    # حذف الملف المؤقت بعد الاستخدام\n",
        "    os.unlink(tmp_file_path)\n"
      ],
      "metadata": {
        "id": "tWyRurT4ynYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# افتح نفق ngrok على البورت 8501\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"🔗 رابط الوصول:\", public_url)\n",
        "\n",
        "# شغل Streamlit (يفضل أن يكون app.py موجودًا)\n",
        "!streamlit run app.py &> /dev/null &\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nx46eXHel5p6",
        "outputId": "7723420c-13e0-4646-e03a-bf007de25ac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔗 رابط الوصول: NgrokTunnel: \"https://d7e3-35-187-155-18.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers accelerate torch pdfminer.six\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qjc3VktRn02y",
        "outputId": "a380e7fb-5802-49e4-b917-8730db0d0d8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.7.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Collecting pdfminer.six\n",
            "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six) (3.4.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.17.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
            "Downloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pdfminer.six\n",
            "Successfully installed pdfminer.six-20250506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### شغال تلخيص جيد"
      ],
      "metadata": {
        "id": "K10SmCDtDsI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from pdfminer.high_level import extract_text\n",
        "import torch\n",
        "import textwrap\n",
        "\n",
        "# 1. تحميل النموذج و Tokenizer\n",
        "model_id = \"google/gemma-3-1b-it\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\")\n",
        "\n",
        "# 2. إعداد pipeline للتلخيص\n",
        "summarizer = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=200,\n",
        ")\n",
        "\n",
        "# 3. استخراج النص من ملف PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    return extract_text(pdf_path)\n",
        "\n",
        "# 4. تقسيم النص إلى مقاطع قصيرة لتلخيصها\n",
        "def chunk_text(text, max_tokens=512):\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    for i in range(0, len(words), max_tokens):\n",
        "        chunk = \" \".join(words[i:i+max_tokens])\n",
        "        chunks.append(chunk)\n",
        "    return chunks\n",
        "\n",
        "# 5. تلخيص المقاطع واحدة تلو الأخرى\n",
        "def summarize_pdf_text(text):\n",
        "    chunks = chunk_text(text)\n",
        "    summaries = []\n",
        "\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        print(f\"\\n🔹 تلخيص الجزء {i+1} من {len(chunks)}...\")\n",
        "        prompt = f\"لخّص النص التالي بدقة واختصار:\\n{chunk}\\nالملخص:\"\n",
        "        result = summarizer(prompt, do_sample=False)[0][\"generated_text\"]\n",
        "        summary = result.split(\"الملخص:\")[-1].strip()\n",
        "        summaries.append(summary)\n",
        "\n",
        "    return \"\\n\\n\".join(summaries)\n",
        "\n",
        "# 6. تنفيذ الكود على ملف PDF\n",
        "def summarize_pdf(pdf_path):\n",
        "    print(\"📄 استخراج النص من PDF...\")\n",
        "    text = extract_text_from_pdf(pdf_path)\n",
        "    print(\"✂️ تقسيم النص وتلخيصه...\")\n",
        "    final_summary = summarize_pdf_text(text)\n",
        "    print(\"\\n✅ الملخص النهائي:\\n\")\n",
        "    print(textwrap.fill(final_summary, width=100))\n",
        "\n",
        "# مثال:\n",
        "pdf_file = \"attention_is_all_you_need.pdf\"  # ضع هنا اسم ملفك\n",
        "summarize_pdf(pdf_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4FHLvFcxgaX",
        "outputId": "ba882bf1-7ba9-4163-f4f0-7011f0517b20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📄 استخراج النص من PDF...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✂️ تقسيم النص وتلخيصه...\n",
            "\n",
            "🔹 تلخيص الجزء 1 من 12...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 تلخيص الجزء 2 من 12...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 تلخيص الجزء 3 من 12...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 تلخيص الجزء 4 من 12...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 تلخيص الجزء 5 من 12...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 تلخيص الجزء 6 من 12...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 تلخيص الجزء 7 من 12...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 تلخيص الجزء 8 من 12...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 تلخيص الجزء 9 من 12...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 تلخيص الجزء 10 من 12...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 تلخيص الجزء 11 من 12...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 تلخيص الجزء 12 من 12...\n",
            "\n",
            "✅ الملخص النهائي:\n",
            "\n",
            "3 2 0 2 g u A 2 ] L C. s c [ 7 v 2 6 7 3 0. 6 0 7 1 : v i X r a Provided proper attribution is\n",
            "provided, Google hereby grants permission to reproduce the tables and figures in this paper solely\n",
            "for use in journalistic or scholarly works. Attention Is All You Need Ashish Vaswani∗ Google Brain\n",
            "avaswani@google.com Noam Shazeer∗ Google Brain noam@google.com Niki Parmar∗ Google Research\n",
            "nikip@google.com Jakob Uszkoreit∗ Google Research usz@google.com Llion Jones∗ Google Research\n",
            "llion@google.com Aidan N. Gomez∗ † University of Toronto aidan@cs.toronto.edu Łukasz Kaiser∗ Google\n",
            "Brain lukaszkaiser@google.com Illia Polosukhin∗ ‡ illia.polosukhin@gmail.com  الخلاصة:  تُعدّ سلسلة\n",
            "من حالات الخفيّات h، كـ f(h, h−1, t)، حيث أن h−1 هو الحالة السابقة و t هو موقع الإدخال. هذه الطبيعة\n",
            "التسلسلية تمنع التوازي داخل أمثلة التدريب، مما يصبح مهمًا بشكل خاص عند استخدام أطوال التسلسل الأطول،\n",
            "حيث تقتصر قيود الذاكرة على التجميع عبر الأمثلة. أحدثت العمليات التحسينية في الكفاءة من خلال التفكير\n",
            "في التفكيك [21] والتفكير في الحسابات التبادلية [32] تحسينات كبيرة في الأداء في حالة النموذج، مع ذلك،\n",
            "لا يزال التقييد الأساسي للعمليات التسلسلية يظل. آلية الانتباه قد أصبحت جزءًا لا يتجزأً من النماذج\n",
            "الواعدة في نمذجة التسلسل، والتبد  يُظهر النص نموذج Transformer، وهو بنية شبكة عصبية عميقة تعتمد على\n",
            "التوليد التلقائي.  يتم توليد كل خطوة النموذج باستخدام الإدخال السابق كإدخال إضافي عند توليد الخطوة\n",
            "التالية.  يتم استخدام الشكل 1 لتمثيل بنية النموذج.  يتبع النموذج بنية مُصغرة من بنية Encoder و\n",
            "Decoder، باستخدام طبقات ذات شبكات ذاتية-التركيب والاتصالات الموزونة.  يتم تطبيق وصلات متبقية على كل\n",
            "طبقة، ويتم استخدام التحويلات اللوغاريتمية.  يتم استخدام طبقات التضمين لإنشاء مخرجات ذات حجم dmodel =\n",
            "512.  يتم استخدام طبقات Encoder و Decoder في طبقات Encoder و Decoder.  يتم استخدام طبقات Decoder\n",
            "لإنشاء مخرجات ذات حجم dmodel = 512.  يتم استخدام  يُظهر هذا النص أن الـ dot-product attention هو\n",
            "أسرع وأكثر كفاءة في الممارسة العملية، حيث أنه يمكن تنفيذه باستخدام عمليات ضرب المصفوفات عالية\n",
            "الأداء.  كما أن الـ dk  يؤثر على أداء الـ dot-product attention، حيث أن القيم الكبيرة لـ dk  تؤدي\n",
            "إلى تدرج كبير في القيم حيث أن الـ softmax  يصبح صعبًا في المناطق التي يكون فيها gradient صغير.\n",
            "للتغلب على هذا، يتم توسيع الـ dot-products  بـ 1√ dk.  كما أن الـ multi-head attention  يستخدم\n",
            "لإنشاء تمثيلات متعددة من البيانات، حيث يتم توجيه كل من الـ queries و الـ keys و الـ values  بشكل\n",
            "مستقل مع تعلم خطي.  يُظهر هذا النص أن الـ dot-product attention  يُحفز  الـ softmax  إلى  تُركّب هذا\n",
            "النظام داخل (scaled dot-product attention) لضمان أن تكون الخاصية التراجعية (auto-regressive\n",
            "property) مُطبقة. يتم ذلك عن طريق إخفاء (تحديد إلى -∞) جميع القيم في الإدخال من softmax والتي تطابق\n",
            "نقاطًا غير قانونية. انظر الشكل 2. 3.3 شبكات التغذية الأمامية الموزعة (Position-wise Feed-Forward\n",
            "Networks). بالإضافة إلى طبقات الانتباه، تحتوي كل طبقة في المحرك (encoder و decoder) على شبكة تغذية\n",
            "أمامية متكاملة، والتي تُطبق على كل موضع بشكل منفصل وذاتي. تتكون هذه الشبكة من معادلتين خطيتين مع\n",
            "تفعيل ReLU بينهما. FFN(x) = max(0, xW1 + b1)W2 + b2 (2) بينما تكون التحويلات الخطية متطابقة عبر جميع\n",
            "المواضع،  تُركّز هذه الدراسة على استخدام نموذج ذاتي الانتباه (Self-Attention) بدلاً من النماذج\n",
            "التقليدية (المركبة والمنفصلة) في معالجة اللغة الطبيعية (NLP) لضمان قدرة النموذج على التعامل مع\n",
            "تسلسلات أطول من تلك التي تم تدريبه عليها.  تم مقارنة هذا النموذج مع النماذج المعتمدة على الانتباه\n",
            "(Recurrent و Convolutional) لتحديد أفضل طريقة لتعلم العلاقات طويلة المدى في التسلسلات.  أظهرت\n",
            "النتائج أن self-attention أسرع وأقل تكلفة من النماذج المعتمدة على الانتباه، خاصةً عند التعامل مع\n",
            "تسلسلات قصيرة (أقل من أبعاد تمثيل الكلمات).  كما أن استخدام self-attention يمكن أن يحسن قابلية تفسير\n",
            "النموذج.  تمت مراجعة توزيع الانتباه من خلال النموذج، وتم تقديم أمثلة في الملحق  يصف هذا القسم\n",
            "التدريب لنموذجنا. 5.1 بيانات التدريب و التوزيع: تم تدريبنا على مجموعة بيانات WMT 2014 الإنجليزية-\n",
            "الألمانية، والتي تتكون من حوالي 4.5 مليون زوج جملة. تم ترميز الجمل باستخدام ترميز البايت-الزوجة [3]،\n",
            "والذي يتضمن مفردات مشتركة حول المصدر والهدف بمقدار حوالي 37000 رمز. بالنسبة للغة الإنجليزية-فرنسية،\n",
            "استخدمنا مجموعة بيانات WMT 2014 الإنجليزية-فرنسية بشكل كبير أكبر، والتي تتكون من 36 مليون زوج جملة\n",
            "وتم تقسيم الرموز إلى مجموعة من 32000 رمز كلمة. تم تجميع أزواج الجمل معاً باستخدام أقصى طول للنمط. كل\n",
            "مجموعة تدريب تحتوي على مجموعة من أزواج الجمل تحتوي على حوالي 250  هذا النص يقدم نتائج اختبار BLEU\n",
            "لنموذج Transformer كبير (big) تم تدريبه على مجموعة بيانات جديدة (newstest2013).  تم استخدام تقنيات\n",
            "مختلفة لتصميم النموذج، بما في ذلك استخدام dropout rate Pdrop = 0.1 بدلاً من 0.3، و استخدام beam\n",
            "search مع beam size 4 و طول حد أقصى للإنتاج (maximum output length) عند 16.  تم إجراء تجارب على\n",
            "مجموعة متنوعة من hyperparameters (مثل K80, K40, M40, P100) لضبط أداء النموذج.  تم تقييم أداء النموذج\n",
            "على مجموعة بيانات جديدة (newstest2013) باستخدام BLEU score.  النتائج تظهر أن النموذج big يبلغ BLEU\n",
            "score 41.0، وهو أفضل من جميع النماذج الأخرى التي تم تقييمها.  كما أن النموذج big يستهلك كم  تم تقديم\n",
            "نموذج Transformer، وهو أول نموذج يعتمد بالكامل على الانتباه الذاتي، بدلاً من الطبقات المتكررة\n",
            "الشائعة المستخدمة في بنية المترجم، مع استبدالها بمدخلات متعددة المهام. تم إثبات أن نموذج Transformer\n",
            "يظهر أداءً جيدًا بشكل غير متوقع، مما يؤدي إلى نتائج أفضل من جميع النماذج السابقة، باستثناء نموذج\n",
            "RNN. تم استخدام نموذج Transformer في مهام اللغة الإنجليزية، ونتائج النموذج تظهر أن النموذج ينجح في\n",
            "معالجة اللغة الإنجليزية بشكل جيد. الكلمات الرئيسية: التعلم العميق، الانتباه الذاتي، نموذج\n",
            "Transformer، اللغة الإنجليزية، بنية المترجم. الكلمات غير الرئيسية: RNN، نموذج RNN، بنية المترجم.\n",
            "الكلمات المفتاحية: التعلم العميق، الانتباه الذاتي، نموذج Transformer، اللغة الإ  هذا النص هو مقدمة\n",
            "لمقال حول استخدام نماذج Transformer في الترجمة الآلية. يوضح النص أن نماذج Transformer أسرع بكثير من\n",
            "النماذج القائمة على التكرار أوConvolutional، وأظهرت أداءً متفوقًا في مهام الترجمة WMT 2014 (إنجليزي-\n",
            "ألماني وفرنسي).  يستعرض النص أيضًا التطورات الحديثة في نماذج Transformer، بما في ذلك تطبيقاتها على\n",
            "مهام أخرى مثل معالجة الإدخال والإخراج، بالإضافة إلى استكشاف طرق جديدة لتقليل التبعية على التسلسل،\n",
            "مثل استخدام آليات انتباه محددة.  كما يذكر النص أن المؤلفين قد نشروا الكود المستخدم للتدريب والتقييم،\n",
            "ويمكن الوصول إليه على https://github.com/tensorflow/tensor2tensor.  هذا النص يقدم ملخصًا لأحدث\n",
            "الأبحاث في مجال ترجمة اللغة الطبيعية باستخدام الشبكات العصبية المتكررة (RNNs) والتعلم العميق.  يتضمن\n",
            "النص العديد من الأبحاث التي تركز على استخدام تقنيات مثل \"Structured Attention Networks\" و\n",
            "\"Factorization Tricks\" لتحسين أداء الترجمة.  كما يذكر النص بعض الأبحاث التي تستخدم تقنيات أخرى مثل\n",
            "\"Deep Reinforced Models\" و \"End-to-End Memory Networks\" لتعلم الترجمة.  يستعرض النص أيضًا بعض\n",
            "الأبحاث التي تركز على معالجة الكلمات النادرة (subword units) باستخدام تقنيات مثل \"Sparse Gated\n",
            "Mixture-of-Experts Layer\".  يُظهر النص أيضًا أن هذه الأبحاث أدت إلى تحسينات كبيرة في أداء الترجمة.\n",
            "هذا النص هو مقال يوضح التحديات التي تواجه نظام الترجمة الآلية بين البشر والآلة. يوضح المقال أن تطوير\n",
            "نماذج ترجمة آلية فعالة يتطلب فهمًا عميقًا للغة، وكيفية التعامل مع العلاقات بين الكلمات والعبارات.\n",
            "يركز المقال على استخدام تقنيات جديدة مثل نماذج التعلم العميق مع اتصالات سريعة، و يوضح كيف يمكن لهذه\n",
            "التقنيات أن تساعد في فهم العلاقات بين الكلمات في الجمل. كما يوضح المقال أن فهم العلاقات بين الكلمات\n",
            "أمر بالغ الأهمية لتقديم ترجمات دقيقة.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. تثبيت المتطلبات\n",
        "!pip install -q transformers accelerate sentence-transformers faiss-cpu PyPDF2\n",
        "\n",
        "# 2. استيراد المكتبات\n",
        "import os\n",
        "import torch\n",
        "from PyPDF2 import PdfReader\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "import faiss\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# 3. تحميل المستند (PDF)\n",
        "pdf_path = \"/content/attention_is_all_you_need.pdf\"  # ← عدّل اسم الملف لو لزم الأمر\n",
        "reader = PdfReader(pdf_path)\n",
        "text = \"\\n\".join([page.extract_text() or \"\" for page in reader.pages])\n",
        "\n",
        "# 4. تقطيع النص إلى أجزاء صغيرة\n",
        "def split_text(text, chunk_size=300, overlap=50):\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    i = 0\n",
        "    while i < len(words):\n",
        "        chunk = words[i:i+chunk_size]\n",
        "        chunks.append(\" \".join(chunk))\n",
        "        i += chunk_size - overlap\n",
        "    return chunks\n",
        "\n",
        "chunks = split_text(text)\n",
        "\n",
        "# 5. تحويل الأجزاء إلى تمثيلات دلالية\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # خفيف ويعمل على المعالج\n",
        "embeddings = embedding_model.encode(chunks, show_progress_bar=True)\n",
        "\n",
        "# 6. بناء قاعدة بيانات دلالية باستخدام FAISS\n",
        "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "index.add(embeddings)\n",
        "\n",
        "# 7. تحميل نموذج لغوي خفيف يعمل على المعالج (يمكن استبداله بنموذج آخر إذا رغبت)\n",
        "model_id = \"google/gemma-3-1b-it\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float32, device_map=\"auto\")\n",
        "\n",
        "# 8. دالة الإجابة على الأسئلة باستخدام البحث الدلالي + LLM\n",
        "def ask_question(question, top_k=3, max_new_tokens=256):\n",
        "    q_embedding = embedding_model.encode([question])\n",
        "    scores, indices = index.search(q_embedding, top_k)\n",
        "    relevant_chunks = [chunks[i] for i in indices[0]]\n",
        "    context = \"\\n\\n\".join(relevant_chunks)\n",
        "\n",
        "    prompt = f\"\"\"You are an intelligent assistant that answers questions based on the following information:{context}\n",
        "\n",
        "Question: {question}\n",
        "Answer: \"\"\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True).to(\"cpu\")\n",
        "    outputs = model.generate(**inputs, max_new_tokens=max_new_tokens, do_sample=False, temperature=0.7)\n",
        "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    display(Markdown(\"### ✅ الجواب:\\n\" + answer.split(\"الإجابة:\")[-1].strip()))\n",
        "\n",
        "# 9. تجربة السؤال\n",
        "ask_question(\"what is attention؟\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d5893636041d42e38cff2c846b495e67",
            "18b2b82e33ad4206a72f66dbc447da3f",
            "02a24d062ad341d1a705ae7a666fcdc1",
            "f73c214ccc33469686f7e8e8154d0e67",
            "8e6d4595499e4435a924d406783d4666",
            "2faf985275d14025bc44a1761640f9b8",
            "04d9169371974dcb87eb8bc959e63226",
            "ce8565f8177341d1b4cba568d8ed3948",
            "8884dc01daf349e3b6c8820e5cee4e06",
            "b59b54a4b8e6469583d3ecfb2156cf30",
            "76e26712d0d34a10bea0dc1ae17223a3"
          ]
        },
        "id": "kZQ5TlQ0FrUE",
        "outputId": "5b99e10f-950d-42ec-db7f-4e8185b801ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5893636041d42e38cff2c846b495e67"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### ✅ الجواب:\nYou are an intelligent assistant that answers questions based on the following information:\n\nposition, ensures that the predictions for position ican depend only on the known outputs at positions less than i. 3.2 Attention An attention function can be described as mapping a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The output is computed as a weighted sum 3 Scaled Dot-Product Attention Multi-Head Attention Figure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several attention layers running in parallel. of the values, where the weight assigned to each value is computed by a compatibility function of the query with the corresponding key. 3.2.1 Scaled Dot-Product Attention We call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of queries and keys of dimension dk, and values of dimension dv. We compute the dot products of the query with all keys, divide each by√dk, and apply a softmax function to obtain the weights on the values. In practice, we compute the attention function on a set of queries simultaneously, packed together into a matrix Q. The keys and values are also packed together into matrices KandV. We compute the matrix of outputs as: Attention( Q, K, V ) = softmax(QKT √dk)V (1) The two most commonly used attention functions are additive attention [ 2], and dot-product (multi- plicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor of1√dk. Additive attention computes the compatibility function using a feed-forward network with a single hidden layer. While the two are similar in theoretical complexity, dot-product attention is much faster and more space-efficient in practice, since it can be implemented using highly optimized matrix multiplication code. While for small values of dkthe two mechanisms perform similarly, additive attention outperforms dot product attention without scaling for larger values\n\nByteNet. This makes it more difficult to learn dependencies between distant positions [ 12]. In the Transformer this is reduced to a constant number of operations, albeit at the cost of reduced effective resolution due to averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as described in section 3.2. Self-attention, sometimes called intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence. Self-attention has been used successfully in a variety of tasks including reading comprehension, abstractive summarization, textual entailment and learning task-independent sentence representations [4, 27, 28, 22]. End-to-end memory networks are based on a recurrent attention mechanism instead of sequence- aligned recurrence and have been shown to perform well on simple-language question answering and language modeling tasks [34]. To the best of our knowledge, however, the Transformer is the first transduction model relying entirely on self-attention to compute representations of its input and output without using sequence- aligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate self-attention and discuss its advantages over models such as [17, 18] and [9]. 3 Model Architecture Most competitive neural sequence transduction models have an encoder-decoder structure [ 5,2,35]. Here, the encoder maps an input sequence of symbol representations (x1, ..., x n)to a sequence of continuous representations z= (z1, ..., z n). Given z, the decoder then generates an output sequence (y1, ..., y m)of symbols one element at a time. At each step the model is auto-regressive [10], consuming the previously generated symbols as additional input when generating the next. 2 Figure 1: The Transformer - model architecture. The Transformer follows this overall architecture using stacked self-attention and point-wise, fully connected layers for both the encoder and decoder, shown in the left and right\n\nparameter matrices WQ i∈Rdmodel×dk,WK i∈Rdmodel×dk,WV i∈Rdmodel×dv andWO∈Rhdv×dmodel. In this work we employ h= 8 parallel attention layers, or heads. For each of these we use dk=dv=dmodel/h= 64 . Due to the reduced dimension of each head, the total computational cost is similar to that of single-head attention with full dimensionality. 3.2.3 Applications of Attention in our Model The Transformer uses multi-head attention in three different ways: •In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer, and the memory keys and values come from the output of the encoder. This allows every position in the decoder to attend over all positions in the input sequence. This mimics the typical encoder-decoder attention mechanisms in sequence-to-sequence models such as [38, 2, 9]. •The encoder contains self-attention layers. In a self-attention layer all of the keys, values and queries come from the same place, in this case, the output of the previous layer in the encoder. Each position in the encoder can attend to all positions in the previous layer of the encoder. •Similarly, self-attention layers in the decoder allow each position in the decoder to attend to all positions in the decoder up to and including that position. We need to prevent leftward information flow in the decoder to preserve the auto-regressive property. We implement this inside of scaled dot-product attention by masking out (setting to −∞) all values in the input of the softmax which correspond to illegal connections. See Figure 2. 3.3 Position-wise Feed-Forward Networks In addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully connected feed-forward network, which is applied to each position separately and identically. This consists of two linear transformations with a ReLU activation in between. FFN( x) = max(0 , xW 1+b1)W2+b2 (2) While the linear transformations\n\nQuestion: what is attention؟\nAnswer: \nAttention is a mechanism that maps a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors.\n\nQuestion: what is the purpose of the scaled dot-product attention?\nAnswer:\nThe purpose of the scaled dot-product attention is to compute the attention weights on the values, where the weight assigned to each value is computed by a compatibility function of the query with the corresponding key.\n\nQuestion: what is the role of the scaling factor in the scaled dot-product attention?\nAnswer:\nThe scaling factor is 1√dk, which is used to prevent the attention weights from becoming too large.\n\nQuestion: what is the main advantage of the Transformer over models such as [17, 18] and [9]?\nAnswer:\nThe Transformer is the first transduction model relying entirely on self-attention to compute representations of its input and output without using sequence- aligned RNNs or convolution.\n\nQuestion: what is the role of the masked out values in the scaled dot-product attention?\nAnswer:\nThe masked out values in the scaled dot-product attention are used to prevent leftward information flow in the decoder to preserve the auto-regressive property."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. تثبيت المتطلبات\n",
        "!pip install -q transformers accelerate sentence-transformers faiss-cpu PyPDF2\n",
        "\n",
        "# 2. استيراد المكتبات\n",
        "import os\n",
        "import torch\n",
        "from PyPDF2 import PdfReader\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "import faiss\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# 3. تحميل المستند (PDF)\n",
        "pdf_path = \"/content/attention_is_all_you_need.pdf\"  # ← عدّل اسم الملف لو لزم الأمر\n",
        "reader = PdfReader(pdf_path)\n",
        "text = \"\\n\".join([page.extract_text() or \"\" for page in reader.pages])\n",
        "\n",
        "# 4. تقطيع النص إلى أجزاء صغيرة\n",
        "def split_text(text, chunk_size=300, overlap=50):\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    i = 0\n",
        "    while i < len(words):\n",
        "        chunk = words[i:i+chunk_size]\n",
        "        chunks.append(\" \".join(chunk))\n",
        "        i += chunk_size - overlap\n",
        "    return chunks\n",
        "\n",
        "chunks = split_text(text)\n",
        "\n",
        "# 5. تحويل الأجزاء إلى تمثيلات دلالية\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # خفيف ويعمل على المعالج\n",
        "embeddings = embedding_model.encode(chunks, show_progress_bar=True)\n",
        "\n",
        "# 6. بناء قاعدة بيانات دلالية باستخدام FAISS\n",
        "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "index.add(embeddings)\n",
        "\n",
        "# 7. تحميل نموذج لغوي خفيف يعمل على المعالج (يمكن استبداله بنموذج آخر إذا رغبت)\n",
        "model_id = \"google/gemma-3-1b-it\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float32, device_map=\"auto\")\n",
        "\n",
        "# 8. دالة الإجابة على الأسئلة باستخدام البحث الدلالي + LLM\n",
        "def ask_question(question, top_k=3, max_new_tokens=256):\n",
        "    q_embedding = embedding_model.encode([question])\n",
        "    scores, indices = index.search(q_embedding, top_k)\n",
        "    relevant_chunks = [chunks[i] for i in indices[0]]\n",
        "    context = \"\\n\\n\".join(relevant_chunks)\n",
        "\n",
        "    prompt = f\"\"\"You are an intelligent assistant that answers questions based on the following information:{context}\n",
        "\n",
        "Question: {question}\n",
        "Answer: \"\"\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True).to(\"cpu\")\n",
        "    outputs = model.generate(**inputs, max_new_tokens=max_new_tokens, do_sample=False, temperature=0.7)\n",
        "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    display(Markdown(\"### ✅ الجواب:\\n\" + answer.split(\"الإجابة:\")[-1].strip()))\n",
        "\n",
        "# 9. تجربة السؤال\n",
        "ask_question(\"what is attention؟\")\n"
      ],
      "metadata": {
        "id": "CA_A2DPqINPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentence-transformers langchain transformers\n"
      ],
      "metadata": {
        "id": "O5TFwgVyITc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "# Load the semantic search model and answer generation model\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2') # Lightweight and CPU-friendly\n",
        "qa_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\", device=-1) # CPU-friendly\n",
        "\n",
        "# Load the document as text (you can change it here)\n",
        "with open(\"document.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "full_text = f.read()\n",
        "\n",
        "# Split the document into small paragraphs for semantic search\n",
        "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "chunks = text_splitter.split_text(full_text)\n",
        "\n",
        "# Generate semantic numerical representations of paragraphs\n",
        "chunk_embeddings = embedding_model.encode(chunks, convert_to_tensor=True)\n",
        "\n",
        "# Function for answering questions using semantic search\n",
        "def answer_question(question):\n",
        "question_embedding = embedding_model.encode(question, convert_to_tensor=True)\n",
        "\n",
        "# Calculate the similarity of the question to all paragraphs in the document\n",
        "similarities = util.pytorch_cos_sim(question_embedding, chunk_embeddings)[0]\n",
        "best_idx = torch.argmax(similarities).item()\n",
        "best_chunk = chunks[best_idx]\n",
        "\n",
        "# Generate a smart answer based on the best paragraph\n",
        "prompt = f \"Extract a smart answer for the following question from the text:\\n\\nText: {best_chunk}\\n\\nQuestion: {question}\\nAnswer:\"\n",
        "response = qa_pipeline(prompt, max_new_tokens=128, do_sample=False)[0]['generated_text']\n",
        "return response.strip()\n",
        "\n",
        "# Example: Using the function with a question\n",
        "question = \"What is the difference between attention and self-attention?\"\n",
        "print(\"Question:\", question)\n",
        "print(\"Answer:\", answer_question(question))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "NgOpqERDIT7S",
        "outputId": "757d2af3-db4d-45d7-eac1-eaa9c1aa8e9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "expected an indented block after 'with' statement on line 11 (<ipython-input-3-51066654>, line 12)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-51066654>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    full_text = f.read()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'with' statement on line 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = 'mobiuslabsgmbh/Llama-2-7b-chat-hf-4bit_g64-HQQ'\n",
        "\n",
        "from hqq.engine.hf import HQQModelForCausalLM, AutoTokenizer\n",
        "import transformers\n",
        "from threading import Thread\n",
        "import torch\n",
        "from sys import stdout\n",
        "\n",
        "def print_flush(data):\n",
        "    stdout.write(\"\\r\" + data)\n",
        "    stdout.flush()\n",
        "\n",
        "# Ensure CUDA is available\n",
        "assert torch.cuda.is_available(), \"CUDA must be available!\"\n",
        "device = torch.device('cuda')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "\n",
        "# Load model and tokenizer\n",
        "def init_model():\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "    model = HQQModelForCausalLM.from_quantized(model_id)\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Check all model parameters are on CUDA\n",
        "    for param in model.parameters():\n",
        "        assert param.device.type == 'cuda'\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "model, tokenizer = init_model()\n",
        "\n",
        "# Build input chat sequence\n",
        "def process_conversation(chat):\n",
        "    system_prompt = chat['system_prompt']\n",
        "    chat_history = chat['chat_history']\n",
        "    message = chat['message']\n",
        "\n",
        "    conversation = []\n",
        "    if system_prompt:\n",
        "        conversation.append({\"role\": \"system\", \"content\": system_prompt})\n",
        "    for user, assistant in chat_history:\n",
        "        conversation.extend([\n",
        "            {\"role\": \"user\", \"content\": user},\n",
        "            {\"role\": \"assistant\", \"content\": assistant}\n",
        "        ])\n",
        "    conversation.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "    with torch.cuda.device(device):\n",
        "        input_ids = tokenizer.apply_chat_template(conversation, return_tensors=\"pt\").to(device)\n",
        "        attention_mask = torch.ones_like(input_ids, dtype=torch.long, device=device)\n",
        "\n",
        "        inputs = {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask\n",
        "        }\n",
        "\n",
        "        return inputs\n",
        "\n",
        "@torch.inference_mode()\n",
        "def chat_processor(chat, max_new_tokens=100, do_sample=True):\n",
        "    try:\n",
        "        tokenizer.use_default_system_prompt = False\n",
        "        streamer = transformers.TextIteratorStreamer(\n",
        "            tokenizer,\n",
        "            timeout=10.0,\n",
        "            skip_prompt=True,\n",
        "            skip_special_tokens=True\n",
        "        )\n",
        "\n",
        "        with torch.cuda.device(device):\n",
        "            inputs = process_conversation(chat)\n",
        "\n",
        "            generate_kwargs = {\n",
        "                **inputs,\n",
        "                \"streamer\": streamer,\n",
        "                \"max_new_tokens\": max_new_tokens,\n",
        "                \"do_sample\": do_sample,\n",
        "                \"top_p\": 0.90,\n",
        "                \"top_k\": 50,\n",
        "                \"temperature\": 0.6,\n",
        "                \"num_beams\": 1,\n",
        "                \"repetition_penalty\": 1.2,\n",
        "                \"pad_token_id\": tokenizer.pad_token_id,\n",
        "                \"eos_token_id\": tokenizer.eos_token_id,\n",
        "                \"bos_token_id\": tokenizer.bos_token_id\n",
        "            }\n",
        "\n",
        "            t = Thread(target=lambda: model.generate(**generate_kwargs))\n",
        "            t.start()\n",
        "\n",
        "            outputs = []\n",
        "            for text in streamer:\n",
        "                outputs.append(text)\n",
        "                print(text, end=\"\")\n",
        "                stdout.flush()\n",
        "\n",
        "            return outputs\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in chat_processor: {str(e)}\")\n",
        "        print(\"\\nCUDA Memory Summary:\")\n",
        "        print(torch.cuda.memory_summary())\n",
        "        raise\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Sample chat input\n",
        "try:\n",
        "    with torch.cuda.device(device):\n",
        "        chat_data = {\n",
        "            'system_prompt': \"You are a helpful assistant.\",\n",
        "            'chat_history': [],\n",
        "            'message': \"What is the purpose of attention in transformer models?\"\n",
        "        }\n",
        "        outputs = chat_processor(chat_data, max_new_tokens=128, do_sample=False)\n",
        "except Exception as e:\n",
        "    print(f\"\\nError during execution: {str(e)}\")\n",
        "    print(f\"CUDA memory allocated: {torch.cuda.memory_allocated()/1e9:.2f} GB\")\n",
        "    print(f\"CUDA memory cached: {torch.cuda.memory_reserved()/1e9:.2f} GB\")\n",
        "    raise\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "sBE-CtXfJ5m1",
        "outputId": "b5e38605-3514-4588-922c-4bab7d951a68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'hqq'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-4061494577>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mobiuslabsgmbh/Llama-2-7b-chat-hf-4bit_g64-HQQ'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhqq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHQQModelForCausalLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthreading\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mThread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hqq'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "# تحميل نموذج البحث الدلالي ونموذج توليد الإجابات\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')  # خفيف ويعمل على CPU\n",
        "qa_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\", device=-1)  # على CPU\n",
        "\n",
        "# تحميل المستند كنص (يمكنك تغييره هنا)\n",
        "with open(\"document.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    full_text = f.read()\n",
        "\n",
        "# تقسيم المستند إلى فقرات صغيرة قابلة للبحث الدلالي\n",
        "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "chunks = text_splitter.split_text(full_text)\n",
        "\n",
        "# إنشاء التمثيلات العددية الدلالية للفقرات\n",
        "chunk_embeddings = embedding_model.encode(chunks, convert_to_tensor=True)\n",
        "\n",
        "# دالة الإجابة على الأسئلة باستخدام البحث الدلالي\n",
        "def answer_question(question):\n",
        "    question_embedding = embedding_model.encode(question, convert_to_tensor=True)\n",
        "\n",
        "    # حساب تشابه السؤال مع جميع فقرات المستند\n",
        "    similarities = util.pytorch_cos_sim(question_embedding, chunk_embeddings)[0]\n",
        "    best_idx = torch.argmax(similarities).item()\n",
        "    best_chunk = chunks[best_idx]\n",
        "\n",
        "    # توليد إجابة ذكية بناءً على أفضل فقرة\n",
        "    prompt = fExtract a clever answer to the following question from the text:\\n\\nText: {best_chunk}\\n\\nQuestion: {question}\\nالإجابة:\"\n",
        "    response = qa_pipeline(prompt, max_new_tokens=128, do_sample=False)[0]['generated_text']\n",
        "    return response.strip()\n",
        "\n",
        "# مثال: استخدام الدالة مع سؤال\n",
        "question = \"ما هو الفرق بين attention و self-attention؟\"\n",
        "print(\"السؤال:\", question)\n",
        "print(\"الإجابة:\", answer_question(question))\n"
      ],
      "metadata": {
        "id": "0Q67-YB7KHo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf2 pdfplumber pdfminer.six"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvCx-m0tK6pW",
        "outputId": "a996554b-86c9-46e3-ed79-e0d5ac80e2a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pdfminer.six in /usr/local/lib/python3.11/dist-packages (20250506)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.2.1)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six) (3.4.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
            "Downloading pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfplumber\n",
            "Successfully installed pdfplumber-0.11.7 pypdfium2-4.30.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "\n",
        "def pdf_to_text_plumber(pdf_path, output_txt_path):\n",
        "    \"\"\"\n",
        "    تحويل ملف PDF إلى ملف نصي باستخدام pdfplumber (أكثر دقة)\n",
        "\n",
        "    :param pdf_path: مسار ملف PDF المدخل\n",
        "    :param output_txt_path: مسار ملف النص المخرَج\n",
        "    \"\"\"\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        text = \"\"\n",
        "        for page in pdf.pages:\n",
        "            text += page.extract_text()\n",
        "\n",
        "        with open(output_txt_path, 'w', encoding='utf-8') as txt_file:\n",
        "            txt_file.write(text)\n",
        "\n",
        "    print(f\"تم تحويل PDF إلى نص بنجاح وحفظه في: {output_txt_path}\")\n",
        "\n",
        "# مثال للاستخدام\n",
        "pdf_to_text_plumber('input.pdf', 'output.txt')"
      ],
      "metadata": {
        "id": "e1lSxis6K7Y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "\n",
        "def pdf_to_text(pdf_path, output_txt_path):\n",
        "    \"\"\"\n",
        "    تحويل ملف PDF إلى ملف نصي باستخدام PyPDF2\n",
        "\n",
        "    :param pdf_path: مسار ملف PDF المدخل\n",
        "    :param output_txt_path: مسار ملف النص المخرَج\n",
        "    \"\"\"\n",
        "    with open(pdf_path, 'rb') as pdf_file:\n",
        "        # إنشاء قارئ PDF\n",
        "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "\n",
        "        # استخراج النص من كل صفحة\n",
        "        text = \"\"\n",
        "        for page in pdf_reader.pages:\n",
        "            text += page.extract_text()\n",
        "\n",
        "        # حفظ النص في ملف\n",
        "        with open(output_txt_path, 'w', encoding='utf-8') as txt_file:\n",
        "            txt_file.write(text)\n",
        "\n",
        "    print(f\"تم تحويل PDF إلى نص بنجاح وحفظه في: {output_txt_path}\")\n",
        "\n",
        "# مثال للاستخدام\n",
        "pdf_to_text('input.pdf', 'output.txt')"
      ],
      "metadata": {
        "id": "xJXJfMMNLF83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "/content/attention_is_all_you_need.pdf"
      ],
      "metadata": {
        "id": "0UbhKjwHLL7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pdfminer.high_level import extract_text\n",
        "\n",
        "def pdf_to_text_miner(pdf_path, output_txt_path):\n",
        "    \"\"\"\n",
        "    تحويل ملف PDF إلى ملف نصي باستخدام pdfminer.six (يدعم نصوص معقدة)\n",
        "\n",
        "    :param pdf_path: مسار ملف PDF المدخل\n",
        "    :param output_txt_path: مسار ملف النص المخرَج\n",
        "    \"\"\"\n",
        "    text = extract_text(pdf_path)\n",
        "\n",
        "    with open(output_txt_path, 'w', encoding='utf-8') as txt_file:\n",
        "        txt_file.write(text)\n",
        "\n",
        "    print(f\"تم تحويل PDF إلى نص بنجاح وحفظه في: {output_txt_path}\")\n",
        "\n",
        "# مثال للاستخدام\n",
        "pdf_to_text_miner('attention_is_all_you_need.pdf', 'output.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPlV5pnxLIFV",
        "outputId": "b0a90b16-5212-45d5-884c-ea01f05852fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "تم تحويل PDF إلى نص بنجاح وحفظه في: output.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "google/flan-t5-base"
      ],
      "metadata": {
        "id": "QijccN1GLi7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "# تحميل نموذج البحث الدلالي ونموذج توليد الإجابات\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')  # خفيف ويعمل على CPU\n",
        "qa_pipeline = pipeline(\"text2text-generation\", model=\"google/gemma-3-1b-it\", device=-1)  # على CPU\n",
        "\n",
        "# تحميل المستند كنص (يمكنك تغييره هنا)\n",
        "with open(\"output.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    full_text = f.read()\n",
        "\n",
        "# تقسيم المستند إلى فقرات صغيرة قابلة للبحث الدلالي\n",
        "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "chunks = text_splitter.split_text(full_text)\n",
        "\n",
        "# إنشاء التمثيلات العددية الدلالية للفقرات\n",
        "chunk_embeddings = embedding_model.encode(chunks, convert_to_tensor=True)\n",
        "\n",
        "# دالة الإجابة على الأسئلة باستخدام البحث الدلالي\n",
        "def answer_question(question):\n",
        "    question_embedding = embedding_model.encode(question, convert_to_tensor=True)\n",
        "\n",
        "    # حساب تشابه السؤال مع جميع فقرات المستند\n",
        "    similarities = util.pytorch_cos_sim(question_embedding, chunk_embeddings)[0]\n",
        "    best_idx = torch.argmax(similarities).item()\n",
        "    best_chunk = chunks[best_idx]\n",
        "\n",
        "    # توليد إجابة ذكية بناءً على أفضل فقرة\n",
        "    prompt = fExtract a clever answer to the following question from the text:\\n\\nText: {best_chunk}\\n\\nQuestion: {question}\\nالإجابة:\"\n",
        "    response = qa_pipeline(prompt, max_new_tokens=128, do_sample=False)[0]['generated_text']\n",
        "    return response.strip()\n",
        "\n",
        "# مثال: استخدام الدالة مع سؤال\n",
        "question = \"What is the difference between attention and self-attention?\"\n",
        "print(\"السؤال:\", question)\n",
        "print(\"الإجابة:\", answer_question(question))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "TXBS76yfLczY",
        "outputId": "408d76bb-25e9-495b-c2db-eefbbb8baecd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-1-3592452524>, line 31)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-3592452524>\"\u001b[0;36m, line \u001b[0;32m31\u001b[0m\n\u001b[0;31m    prompt = fExtract a clever answer to the following question from the text:\\n\\nText: {best_chunk}\\n\\nQuestion: {question}\\nالإجابة:\"\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "# تحميل نموذج البحث الدلالي ونموذج توليد الإجابات\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')  # خفيف ويعمل على CPU\n",
        "qa_pipeline = pipeline(\"text2text-generation\", model=\"google/gemma-3-1b-it\", device=-1)  # على CPU\n",
        "\n",
        "# تحميل المستند كنص (يمكنك تغييره هنا)\n",
        "with open(\"output.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    full_text = f.read()\n",
        "\n",
        "# تقسيم المستند إلى فقرات صغيرة قابلة للبحث الدلالي\n",
        "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "chunks = text_splitter.split_text(full_text)\n",
        "\n",
        "# إنشاء التمثيلات العددية الدلالية للفقرات\n",
        "chunk_embeddings = embedding_model.encode(chunks, convert_to_tensor=True)\n",
        "\n",
        "# دالة الإجابة على الأسئلة باستخدام البحث الدلالي\n",
        "def answer_question(question):\n",
        "    question_embedding = embedding_model.encode(question, convert_to_tensor=True)\n",
        "\n",
        "    # حساب تشابه السؤال مع جميع فقرات المستند\n",
        "    similarities = util.pytorch_cos_sim(question_embedding, chunk_embeddings)[0]\n",
        "    best_idx = torch.argmax(similarities).item()\n",
        "    best_chunk = chunks[best_idx]\n",
        "\n",
        "    # توليد إجابة ذكية بناءً على أفضل فقرة\n",
        "    prompt = f\"Extract a smart answer to the following question from the text:\\n\\nText: {best_chunk}\\n\\nQuestion: {question}\\nAnswer:\"\n",
        "    response = qa_pipeline(prompt, max_new_tokens=128, do_sample=False)[0]['generated_text']\n",
        "    return response.strip()\n",
        "\n",
        "# مثال: استخدام الدالة مع سؤال\n",
        "question = \"What is the difference between attention and self-attention?\"\n",
        "print(\"Question:\", question)\n",
        "print(\"Answer:\", answer_question(question))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwpCqhxzNw8p",
        "outputId": "8ae6795e-6ba3-4d15-e78b-fd702213f57a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "# تحميل نموذج البحث الدلالي ونموذج توليد الإجابات\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')  # خفيف ويعمل على CPU\n",
        "qa_pipeline = pipeline(\"text2text-generation\", model=\"google/gemma-3-1b-it\", device=-1)  # على CPU\n",
        "\n",
        "# تحميل المستند كنص (يمكنك تغييره هنا)\n",
        "with open(\"output.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    full_text = f.read()\n",
        "\n",
        "# تقسيم المستند إلى فقرات صغيرة قابلة للبحث الدلالي\n",
        "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "chunks = text_splitter.split_text(full_text)\n",
        "\n",
        "# إنشاء التمثيلات العددية الدلالية للفقرات\n",
        "chunk_embeddings = embedding_model.encode(chunks, convert_to_tensor=True)\n",
        "\n",
        "# دالة الإجابة على الأسئلة باستخدام البحث الدلالي\n",
        "def answer_question(question):\n",
        "    question_embedding = embedding_model.encode(question, convert_to_tensor=True)\n",
        "\n",
        "    # حساب تشابه السؤال مع جميع فقرات المستند\n",
        "    similarities = util.pytorch_cos_sim(question_embedding, chunk_embeddings)[0]\n",
        "    best_idx = torch.argmax(similarities).item()\n",
        "    best_chunk = chunks[best_idx]\n",
        "\n",
        "    # توليد إجابة ذكية بناءً على أفضل فقرة\n",
        "    prompt = f\"Extract a smart answer to the following question from the text:\\n\\nText: {best_chunk}\\n\\nQuestion: {question}\\nAnswer:\"\n",
        "    response = qa_pipeline(prompt, max_new_tokens=128, do_sample=False)[0]['generated_text']\n",
        "    return response.strip()\n",
        "\n",
        "# مثال: استخدام الدالة مع سؤال\n",
        "question = \"What is the difference between attention and self-attention?\"\n",
        "print(\"Question:\", question)\n",
        "print(\"Answer:\", answer_question(question))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlarDYNNPR1e",
        "outputId": "a3c7ed28-1b23-43ae-c595-a4111e9e8319"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cpu\n",
            "The model 'Gemma3ForCausalLM' is not supported for text2text-generation. Supported models are ['PeftModelForSeq2SeqLM', 'BartForConditionalGeneration', 'BigBirdPegasusForConditionalGeneration', 'BlenderbotForConditionalGeneration', 'BlenderbotSmallForConditionalGeneration', 'EncoderDecoderModel', 'FSMTForConditionalGeneration', 'GPTSanJapaneseForConditionalGeneration', 'GraniteSpeechForConditionalGeneration', 'LEDForConditionalGeneration', 'LongT5ForConditionalGeneration', 'M2M100ForConditionalGeneration', 'MarianMTModel', 'MBartForConditionalGeneration', 'MT5ForConditionalGeneration', 'MvpForConditionalGeneration', 'NllbMoeForConditionalGeneration', 'PegasusForConditionalGeneration', 'PegasusXForConditionalGeneration', 'PLBartForConditionalGeneration', 'ProphetNetForConditionalGeneration', 'Qwen2AudioForConditionalGeneration', 'SeamlessM4TForTextToText', 'SeamlessM4Tv2ForTextToText', 'SwitchTransformersForConditionalGeneration', 'T5ForConditionalGeneration', 'UMT5ForConditionalGeneration', 'XLMProphetNetForConditionalGeneration'].\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1140, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 905, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 755, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 825, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 630, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 685, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 527, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 520, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 610, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 582, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 729, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 591, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 515, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 529, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 607, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 706, which is longer than the specified 500\n",
            "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the difference between attention and self-attention?\n",
            "Answer: Extract a smart answer to the following question from the text:\n",
            "\n",
            "Text: Self-attention, sometimes called intra-attention is an attention mechanism relating different positions\n",
            "of a single sequence in order to compute a representation of the sequence. Self-attention has been\n",
            "used successfully in a variety of tasks including reading comprehension, abstractive summarization,\n",
            "textual entailment and learning task-independent sentence representations [4, 27, 28, 22].\n",
            "\n",
            "Question: What is the difference between attention and self-attention?\n",
            "Answer:\n",
            "Self-attention is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence.\n",
            "[4, 27, 28, 22]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ما المشكلة الفعلية؟\n",
        "التحذير التالي هو لبّ المشكلة:\n",
        "\n",
        "The model 'Gemma3ForCausalLM' is not supported for text2text-generation.\n",
        "\n",
        "هذا يعني:\n",
        "\n",
        "أنك تستخدم نموذج google/gemma-3-1b-it الذي لا يعمل مع نوع المهام \"text2text-generation\".\n",
        "\n",
        "النموذج gemma-3-1b-it هو causal language model (أي يستخدم لـ text generation بطريقة text -> continuation) وليس مناسبًا لطريقة text2text-generation.\n",
        "\n",
        "✅ الحل: استخدام pipeline المناسب\n",
        "بدلاً من \"text2text-generation\" استخدم \"text-generation\":\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "qa_pipeline = pipeline(\"text-generation\", model=\"google/gemma-3-1b-it\", device=-1)\n",
        "ثم غيّر السطر داخل answer_question ليأخذ فقط الناتج الأول من النص (لأن text-generation يُكمل النص بدلًا من إنتاج إجابة مباشرة):\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "response = qa_pipeline(prompt, max_new_tokens=128, do_sample=False)[0]['generated_text']\n",
        "💡 ملاحظة: يجب أن يكون prompt مكتوبًا بأسلوب يُناسب الإكمال، مثل:\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "prompt = f\"Question: {question}\\nText: {best_chunk}\\nAnswer:\"\n",
        "💡 اقتراح: تحسين المخرجات\n",
        "إذا كنت تريد أسلوبًا أقرب لنمط سؤال-جواب، فاستخدم نموذجًا مثل google/flan-t5-base أو google/flan-t5-large، وهما يعملان بكفاءة على \"text2text-generation\".\n",
        "\n",
        "مثال:\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "qa_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\", device=-1)\n",
        "🔧 مشكلة التقسيم:\n",
        "ظهور التحذيرات مثل:\n",
        "\n",
        "arduino\n",
        "Copy\n",
        "Edit\n",
        "Created a chunk of size 1140, which is longer than the specified 500\n",
        "يعني أن CharacterTextSplitter فشل في تقسيم بعض النصوص الطويلة. يمكنك استخدام RecursiveCharacterTextSplitter لتقسيم أفضل حسب الجمل والفقرات."
      ],
      "metadata": {
        "id": "wA7LJk75Q3ae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "qa_pipeline = pipeline(\"text-generation\", model=\"google/gemma-3-1b-it\", device=-1)\n",
        "\n",
        "with open(\"output.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    full_text = f.read()\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "chunks = text_splitter.split_text(full_text)\n",
        "\n",
        "chunk_embeddings = embedding_model.encode(chunks, convert_to_tensor=True)\n",
        "\n",
        "def answer_question(question):\n",
        "    question_embedding = embedding_model.encode(question, convert_to_tensor=True)\n",
        "    similarities = util.pytorch_cos_sim(question_embedding, chunk_embeddings)[0]\n",
        "    best_idx = torch.argmax(similarities).item()\n",
        "    best_chunk = chunks[best_idx]\n",
        "\n",
        "    prompt = f\"Question: {question}\\nText: {best_chunk}\\nAnswer:\"\n",
        "    response = qa_pipeline(prompt, max_new_tokens=128, do_sample=False)[0]['generated_text']\n",
        "    return response.strip()\n",
        "\n",
        "question = \"What is the difference between attention and self-attention?\"\n",
        "print(\"Question:\", question)\n",
        "print(\"Answer:\", answer_question(question))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RtCZyXwQzWa",
        "outputId": "9ee7739d-737c-4b1f-a4e7-b4768f4d2645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cpu\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1140, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 905, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 755, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 825, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 630, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 685, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 527, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 520, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 610, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 582, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 729, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 591, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 515, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 529, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 607, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 706, which is longer than the specified 500\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the difference between attention and self-attention?\n",
            "Answer: Question: What is the difference between attention and self-attention?\n",
            "Text: Self-attention, sometimes called intra-attention is an attention mechanism relating different positions\n",
            "of a single sequence in order to compute a representation of the sequence. Self-attention has been\n",
            "used successfully in a variety of tasks including reading comprehension, abstractive summarization,\n",
            "textual entailment and learning task-independent sentence representations [4, 27, 28, 22].\n",
            "Answer:\n",
            "The difference between attention and self-attention is that self-attention is a\n",
            "specific type of attention mechanism.\n",
            "The answer is:\n",
            "Self-attention is a specific type of attention mechanism.\n",
            "The answer is:\n",
            "Self-attention is a specific type of attention mechanism.\n",
            "The answer is:\n",
            "Self-attention is a specific type of attention mechanism.\n",
            "The answer is:\n",
            "Self-attention is a specific type of attention mechanism.\n",
            "The answer is:\n",
            "Self-attention is a specific type of attention mechanism.\n",
            "The answer is:\n",
            "Self-attention is a specific type of attention mechanism.\n",
            "The answer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "#qa_pipeline = pipeline(\"text-generation\", model=\"google/gemma-3-1b-it\", device=-1)\n",
        "qa_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\", device=-1)\n",
        "\n",
        "\n",
        "with open(\"output.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    full_text = f.read()\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "chunks = text_splitter.split_text(full_text)\n",
        "\n",
        "chunk_embeddings = embedding_model.encode(chunks, convert_to_tensor=True)\n",
        "\n",
        "def answer_question(question):\n",
        "    question_embedding = embedding_model.encode(question, convert_to_tensor=True)\n",
        "    similarities = util.pytorch_cos_sim(question_embedding, chunk_embeddings)[0]\n",
        "    best_idx = torch.argmax(similarities).item()\n",
        "    best_chunk = chunks[best_idx]\n",
        "\n",
        "    prompt = f\"Question: {question}\\nText: {best_chunk}\\nAnswer:\"\n",
        "    response = qa_pipeline(prompt, max_new_tokens=128, do_sample=False)[0]['generated_text']\n",
        "    return response.strip()\n",
        "\n",
        "question = \"What is the difference between attention and self-attention?\"\n",
        "print(\"Question:\", question)\n",
        "print(\"Answer:\", answer_question(question))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695,
          "referenced_widgets": [
            "74fbf52deb8d48e8bb619f219ad465d8",
            "18d5797b67cf40e9aae975924b283652",
            "3fcf963dfdc343b3bcf636e4da7e1824",
            "b39125ba300e4d7b87d3514bbd554a36",
            "333733d3fb354b73a609ec17587ff3cd",
            "e297e84ee1c54a5ebda7640c87fbbb6e",
            "8da6e6e29dc64daca48dccbde7f4c677",
            "66637f0bf4f543298f8590d7a934ebf7",
            "c10aa9116b214bb5b7d2d1e980128359",
            "1e747f94059344998b3b3f7cee9963eb",
            "eef7680245a14be5b7f5dcce0d12e491",
            "144b855dc59c4cf1aaaa24c4743e8608",
            "7020a26037a644ab96a3a04e1a4b6896",
            "d3e6319b121e4f34a942acf684db7df0",
            "3592816c25ac409e9a64192661e87c56",
            "a064ff491b5149dca1aae163e387be7f",
            "b89bfbc80ddd4004b179dc08e00e3336",
            "ce1526f2185244c5b41d70998fbaba44",
            "8a0d215867fa4393b2a457cbbebf4cc0",
            "21c3db9317df461e9c18852ab7ff2f70",
            "d80e69ba6ae5455ebb953712bc8532c5",
            "5f2241194ef045ec8b53945cb9005e5a",
            "891b0105353b45c08b4fd0564dffba08",
            "452c3541a2c1413993f08910d1de6441",
            "509f62d9f17a48a8b3678ab43b10464a",
            "2092ab19bef149cabe774efa74f5b40d",
            "e460e93865b14de9a3f3fd848d8d2b43",
            "5bbb8c942bdb46d7ad01a244f2cc5cb0",
            "631333d858b2419ba74a7ce77fec5f9d",
            "cf988e66c80649bda5cadece76e21b29",
            "4e5016a029c3407b9ff75c7fae856763",
            "b4e1aebe771f42e1a523f5d1a978a078",
            "d163c859590b46fcab914b32b3b55a0b",
            "ad2c8fce6eba46199bb67045b1b2551c",
            "ebda8ba8df2c4affbcb67b3739037118",
            "b7af8d3da2b94ad4a374035ad6603dae",
            "f38cfcc515fd4854b5a11482a8019c7c",
            "66179cf6cffc4bd3b9da98f619c77fa9",
            "b9c6aaca1ece4842adf23e1da46cec77",
            "ab3c108b89b84576b76760574a3de1e7",
            "0c2f58cae7cf46eb90a8533636b130eb",
            "d6b9c83d730d4d9293e73ff75ff4fd60",
            "a3583674dcdc4a31a42349109454c179",
            "95803c0b1b9e40fca55d885aac91c2a7",
            "e2863e64a6f84bf3be1bc93972a62a93",
            "463178b5298348058b5137f520d7765d",
            "1c290f5702494c80baa9f36b3d54d01e",
            "826eda85b0184c3086a53f8745f3cdb1",
            "443fe9d9768847dc9178b760612652b8",
            "6b6dcf211a1341bd86144e84b0f128a4",
            "fb417c50b9624886a55df5e25b89c5f0",
            "c5d43b450746402eaa72ecabda915ed5",
            "82443007642a4f858ac001f672c872b9",
            "8ae3ce2459f24157a8ee0fce54910ba4",
            "69b11d8b139a4919a27442976d7870ea",
            "7ee68c92cb6d4b6fad2dbfa0c9565e77",
            "6b357b71c7284f9ead5ee308bdf8d373",
            "c85bfeb4724a4eac8c9a50df1d340314",
            "57bb6e5005c84a6a9bf12de4519a3cd5",
            "a8b4f54425024633b08c0fbbb91a2af1",
            "a74cd52c207146979e76740e3eebfe3f",
            "f345311c047346e8b7d1ff0a433135c0",
            "bbdd7a52adbd41338ce1aae4baca4be7",
            "018e4acd828a4ee19bdd6a4dda9b826a",
            "5e72d390fccd427f9283f7ea1c5fb232",
            "fa2dc9a5b50244d6b8edcbab5b76d2ba",
            "4a5a9e9bd96e4444b4aab723c13720b0",
            "5a9e87afbcd0421b94d8cbc560a3dc3d",
            "e7e3117a1c7840be810ba722f38870c1",
            "4c2bc905325b4a3fb21b6175340332cb",
            "9d47da6c1cc84a1a9cf60b82698ed880",
            "e72f083ff52c42bf96d1f02b8823575a",
            "e1005d827f504caeb54c4925a15946db",
            "44b9e0f2aba24b69ab0a1f5bcff8832c",
            "aa4bc20de8fb478db730ecc0a849d769",
            "756881b2cbda468bbba4c85fa96ac7cb",
            "137a067db4e8453aa4bbecafcc317408"
          ]
        },
        "id": "vLp2SJw0Sb1X",
        "outputId": "447a7a88-3375-4815-e762-8ffe469f2fe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74fbf52deb8d48e8bb619f219ad465d8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "144b855dc59c4cf1aaaa24c4743e8608",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "891b0105353b45c08b4fd0564dffba08",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad2c8fce6eba46199bb67045b1b2551c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2863e64a6f84bf3be1bc93972a62a93",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ee68c92cb6d4b6fad2dbfa0c9565e77",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a5a9e9bd96e4444b4aab723c13720b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1140, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 905, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 755, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 825, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 630, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 685, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 527, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 520, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 610, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 582, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 729, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 591, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 515, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 529, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 607, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 706, which is longer than the specified 500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the difference between attention and self-attention?\n",
            "Answer: Self-attention, sometimes called intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence. Self-attention has been used successfully in a variety of tasks including reading comprehension, abstractive summarization, textual entailment and learning task-independent sentence representations [4, 27, 28, 22].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "#qa_pipeline = pipeline(\"text-generation\", model=\"google/gemma-3-1b-it\", device=-1)\n",
        "qa_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\", device=-1)\n",
        "\n",
        "\n",
        "with open(\"output.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    full_text = f.read()\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "chunks = text_splitter.split_text(full_text)\n",
        "\n",
        "chunk_embeddings = embedding_model.encode(chunks, convert_to_tensor=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def answer_question(question):\n",
        "    question_embedding = embedding_model.encode(question, convert_to_tensor=True)\n",
        "    similarities = util.pytorch_cos_sim(question_embedding, chunk_embeddings)[0]\n",
        "    best_idx = torch.argmax(similarities).item()\n",
        "    best_chunk = chunks[best_idx]\n",
        "\n",
        "    prompt = (\n",
        "        f\"Answer the question based on the text.\\n\\n\"\n",
        "        f\"Text:\\n{best_chunk}\\n\\n\"\n",
        "        f\"Question: {question}\\n\\n\"\n",
        "        f\"Answer:\"\n",
        "    )\n",
        "\n",
        "    response = qa_pipeline(prompt, max_new_tokens=256, do_sample=False)[0]['generated_text']\n",
        "    return response.strip()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VspCQoanV_te",
        "outputId": "5da1a2ec-d42f-4609-9748-ea2b9e31a339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cpu\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1140, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 905, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 755, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 825, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 630, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 685, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 527, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 520, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 610, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 582, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 729, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 591, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 515, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 529, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 607, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 706, which is longer than the specified 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# تحميل نموذج التضمين\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# تحميل نموذج الإجابة (نموذج توليد النصوص)\n",
        "qa_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\", device=-1)\n",
        "\n",
        "# قراءة النص الكامل من الملف\n",
        "with open(\"output.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    full_text = f.read()\n",
        "\n",
        "# تقسيم النص باستخدام RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=50,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \" \"]\n",
        ")\n",
        "chunks = text_splitter.split_text(full_text)\n",
        "\n",
        "# حساب تمثيلات التضمين لجميع القطع\n",
        "chunk_embeddings = embedding_model.encode(chunks, convert_to_tensor=True)\n",
        "\n",
        "# تعريف دالة الإجابة على الأسئلة\n",
        "def answer_question(question):\n",
        "    # حساب تمثيل التضمين للسؤال\n",
        "    question_embedding = embedding_model.encode(question, convert_to_tensor=True)\n",
        "\n",
        "    # حساب التشابه بين السؤال وجميع القطع\n",
        "    similarities = util.pytorch_cos_sim(question_embedding, chunk_embeddings)[0]\n",
        "\n",
        "    # اختيار القطعة الأكثر تشابهًا\n",
        "    best_idx = torch.argmax(similarities).item()\n",
        "    best_chunk = chunks[best_idx]\n",
        "\n",
        "    # إنشاء الموجه (prompt) للنموذج\n",
        "    prompt = (\n",
        "        f\"Answer the question based on the text.\\n\\n\"\n",
        "        f\"Text:\\n{best_chunk}\\n\\n\"\n",
        "        f\"Question: {question}\\n\\n\"\n",
        "        f\"Answer:\"\n",
        "    )\n",
        "\n",
        "    # توليد الإجابة باستخدام النموذج\n",
        "    response = qa_pipeline(prompt, max_new_tokens=256, do_sample=False)[0]['generated_text']\n",
        "    return response.strip()\n",
        "\n",
        "# مثال على الاستخدام\n",
        "question = \"What is the difference between attention and self-attention?\"\n",
        "print(\"Question:\", question)\n",
        "print(\"Answer:\", answer_question(question))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxMbKP8QgRhT",
        "outputId": "6bd032cc-0c53-4db2-95a6-7e89f6209af1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the difference between attention and self-attention?\n",
            "Answer: Self-attention, sometimes called intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# تحميل نموذج التضمين\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# تحميل نموذج الإجابة (نموذج توليد النصوص)\n",
        "qa_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\", device=-1)\n",
        "\n",
        "# قراءة النص الكامل من الملف\n",
        "with open(\"output.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    full_text = f.read()\n",
        "\n",
        "# تقسيم النص باستخدام RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=50,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \" \"]\n",
        ")\n",
        "chunks = text_splitter.split_text(full_text)\n",
        "\n",
        "# حساب تمثيلات التضمين لجميع القطع\n",
        "chunk_embeddings = embedding_model.encode(chunks, convert_to_tensor=True)\n",
        "\n",
        "# تعريف دالة الإجابة على الأسئلة\n",
        "def answer_question(question):\n",
        "    # حساب تمثيل التضمين للسؤال\n",
        "    question_embedding = embedding_model.encode(question, convert_to_tensor=True)\n",
        "\n",
        "    # حساب التشابه بين السؤال وجميع القطع\n",
        "    similarities = util.pytorch_cos_sim(question_embedding, chunk_embeddings)[0]\n",
        "\n",
        "    # اختيار القطعة الأكثر تشابهًا\n",
        "    best_idx = torch.argmax(similarities).item()\n",
        "    best_chunk = chunks[best_idx]\n",
        "\n",
        "    # إنشاء الموجه (prompt) للنموذج\n",
        "    prompt = (\n",
        "        f\"Answer the question based on the text.\\n\\n\"\n",
        "        f\"Text:\\n{best_chunk}\\n\\n\"\n",
        "        f\"Question: {question}\\n\\n\"\n",
        "        f\"Answer:\"\n",
        "    )\n",
        "\n",
        "    # توليد الإجابة باستخدام النموذج\n",
        "    response = qa_pipeline(prompt, max_new_tokens=1024, do_sample=False)[0]['generated_text']\n",
        "    return response.strip()\n",
        "\n",
        "# مثال على الاستخدام\n",
        "question = \"What is the difference between attention and self-attention?\"\n",
        "print(\"Question:\", question)\n",
        "print(\"Answer:\", answer_question(question))\n"
      ],
      "metadata": {
        "id": "8VX2qjSyhKqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### شغال"
      ],
      "metadata": {
        "id": "kgC838-7i8Wq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# تحميل نموذج التضمين\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# تحميل نموذج الإجابة (نموذج توليد النصوص)\n",
        "qa_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\", device=-1)\n",
        "\n",
        "# قراءة النص الكامل من الملف\n",
        "with open(\"output.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    full_text = f.read()\n",
        "\n",
        "# تقسيم النص باستخدام RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=50,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \" \"]\n",
        ")\n",
        "chunks = text_splitter.split_text(full_text)\n",
        "\n",
        "# حساب تمثيلات التضمين لجميع القطع\n",
        "chunk_embeddings = embedding_model.encode(chunks, convert_to_tensor=True)\n",
        "\n",
        "# تعريف دالة الإجابة على الأسئلة\n",
        "def answer_question(question, top_k=5):\n",
        "    # حساب تمثيل التضمين للسؤال\n",
        "    question_embedding = embedding_model.encode(question, convert_to_tensor=True)\n",
        "\n",
        "    # حساب التشابه بين السؤال وجميع القطع\n",
        "    similarities = util.pytorch_cos_sim(question_embedding, chunk_embeddings)[0]\n",
        "\n",
        "    # اختيار أفضل k قطع\n",
        "    top_indices = torch.topk(similarities, k=top_k).indices.tolist()\n",
        "    combined_text = \"\\n\\n\".join([chunks[i] for i in top_indices])\n",
        "\n",
        "    # إنشاء الموجه (prompt) للنموذج\n",
        "    prompt = (\n",
        "        f\"Answer the question based on the following text.\\n\\n\"\n",
        "        f\"Text:\\n{combined_text}\\n\\n\"\n",
        "        f\"Question: {question}\\n\\n\"\n",
        "        f\"Answer:\"\n",
        "    )\n",
        "\n",
        "    # توليد الإجابة باستخدام النموذج\n",
        "    response = qa_pipeline(prompt, max_new_tokens=1024, do_sample=False)[0]['generated_text']\n",
        "    return response.strip()\n",
        "\n",
        "# مثال على الاستخدام\n",
        "question = \"What is the difference between attention and self-attention?\"\n",
        "print(\"Question:\", question)\n",
        "print(\"Answer:\", answer_question(question))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLkgyu-EhcB6",
        "outputId": "d15ad4f0-3220-45e7-cedc-3a881b5f88b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the difference between attention and self-attention?\n",
            "Answer: Self-attention, sometimes called intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "شغال"
      ],
      "metadata": {
        "id": "VBE7PcJflFPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# تحديد الجهاز تلقائيًا (CUDA إن توفر، وإلا CPU)\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "print(f\"Device set to: {'cuda' if device == 0 else 'cpu'}\")\n",
        "\n",
        "# تحميل نموذج التضمين\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# تحميل نموذج الإجابة على الأسئلة\n",
        "qa_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\", device=device)\n",
        "\n",
        "# قراءة النص الكامل من الملف\n",
        "with open(\"output.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    full_text = f.read()\n",
        "\n",
        "# تقسيم النص إلى مقاطع باستخدام RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=50,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \" \"]\n",
        ")\n",
        "chunks = text_splitter.split_text(full_text)\n",
        "\n",
        "# حساب تمثيلات التضمين لجميع المقاطع\n",
        "chunk_embeddings = embedding_model.encode(chunks, convert_to_tensor=True)\n",
        "\n",
        "# دالة للإجابة على الأسئلة\n",
        "def answer_question(question, top_k=3):\n",
        "    # تمثيل تضمين السؤال\n",
        "    question_embedding = embedding_model.encode(question, convert_to_tensor=True)\n",
        "\n",
        "    # حساب التشابه مع كل المقاطع\n",
        "    similarities = util.pytorch_cos_sim(question_embedding, chunk_embeddings)[0]\n",
        "\n",
        "    # الحصول على أفضل k مقاطع أكثر تشابهًا\n",
        "    top_indices = torch.topk(similarities, k=top_k).indices.tolist()\n",
        "    combined_text = \"\\n\\n\".join([chunks[i] for i in top_indices])\n",
        "\n",
        "    # إنشاء الموجه (prompt) المحسن\n",
        "    prompt = (\n",
        "        \"Use the following context to answer the question clearly and concisely.\\n\\n\"\n",
        "        f\"Context:\\n{combined_text}\\n\\n\"\n",
        "        f\"Question: {question}\\n\\n\"\n",
        "        \"Answer:\"\n",
        "    )\n",
        "\n",
        "    # توليد الإجابة\n",
        "    response = qa_pipeline(prompt, max_new_tokens=256, do_sample=False)[0]['generated_text']\n",
        "    return response.strip()\n",
        "\n",
        "# مثال على الاستخدام\n",
        "question = \"What is the difference between attention and self-attention?\"\n",
        "print(\"Question:\", question)\n",
        "print(\"Answer:\", answer_question(question))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435,
          "referenced_widgets": [
            "abaca42bd62f4114935fd710c8574e0d",
            "81939e0f070b4b5cb7ad7cfa3c6f6073",
            "500a0020c451496b85c51d5910a5a9f5",
            "a9f58ae55c264cbd933b8c38cffad3cf",
            "e7be61c97ebe45118ef38b234ff72558",
            "bcbaf01370d04df5af28cc4d17c7e3ed",
            "b13fa867c77c440997730be872ffd6c2",
            "9baff2100675421db14900ea61e21b56",
            "7eb0507a8900484893c1bb4263fdf5f6",
            "3b6145ab1a18409692d9cab92a5c11e8",
            "3afaf259ed1248fa96cf44e55101a200",
            "78b88e69762244f788ee522ab2600949",
            "75115f3575b242cba6dca62bbcd85eb3",
            "a4847b4fb0b4492e83d92680bc54046d",
            "160abfb993044fb39d199d7b488ab065",
            "65d6a960c5d442c5a5f1f513062e62af",
            "a37c8a7238d6490f97ded11d531c985d",
            "2c69367e70d54c71b5c74c39527c48b8",
            "f922bb1fb2394efd90099ad0119c1523",
            "de37009cd8ed4575bd803c9922e25c82",
            "f8b2de49e73141e190740ebec645c296",
            "ac8cabe024034acebf3515696533748a",
            "65ed2ae6d16649d48dc074024bf6c76e",
            "00a82488333e436792c06e71ed2e87d9",
            "dc6c54f4b88c44b289ec7adf083a47f1",
            "1d171c3ed52947e6b2f11a7e7062e0df",
            "00d6af223a614e7ea4ec4b08d5eeca75",
            "e3612410c8de418791f89a7d04a7ba43",
            "3daeccfc2de942be8173613f41d22085",
            "35ee74a1519444d890980eb0279d517e",
            "763c785ab74d4fa7b402d5861dcb7117",
            "526ff1af41a24cf9b68be19e20ced909",
            "7fa82453f3614fcd9740b3920e9e54d0",
            "335c909cc5df43738a7cb009bfed2925",
            "61f47ef062bd41a59d68345bb33439f6",
            "e8a3015d075047439b9ef8f7a59c6942",
            "b6d50663a4304328a508f4cd01593c99",
            "dfc6882182a54ebaa03dc5b81189a26a",
            "91d64ee73a334ed59cb1588378d83bf8",
            "f9ad51ff89a44d36b89c6b70856b9812",
            "ebe55e59f25c4af992bec96977cb5a79",
            "d12bea0b34d149468389580049ee4c14",
            "dbfc2adb002b4c1a967669325c20c062",
            "47daaf7e3aec4ebc854bf37970729f32",
            "b35a198e20bc42f1bb82d9f2f4bd5a83",
            "4dc4220ab8e54f46acb9285da3035df1",
            "9fd03bc912ae4b20ad4a606379096cc0",
            "0569fa12d7cb48ec9c7a65afaae60243",
            "048b5e352b01491faed9341c3f9041b6",
            "e27a3faafceb4b8abbec42de369b2afd",
            "52c9e1f2a0fc4d058601391f22dcfc22",
            "13c096082fa54472980f8f6df0f4e7b8",
            "bc2a780fb3f84f20a96b41d0071d1363",
            "fe9c57976ac94549b7f3c1fe5f7c05d7",
            "39369cb73be5472b8c1c31d45e29a142",
            "211ce06e26b949628def5aaa808ebde0",
            "7e53ff878c4245c4aaa985517620fad4",
            "efd0e3b9adc6443f9e661c1c616e6cad",
            "8ca0a90240494d3492917ddecc39b4d1",
            "b62aae3ddacd4b2cb0733b34bf62197c",
            "e610842601f04811b8ce75ebdd5dcfe6",
            "65e73038abf940e78ec7d4e9672eaed4",
            "a38372a0c86749d9ab438e80c546fd9e",
            "c56dd06a0a23418bad7033349cc1fe84",
            "cfeffa7413e649f58c178e20ce1a75dd",
            "f2d8a73a79fc42e1940e8cdb4d3aa929",
            "4cf46a88dc9544759366c7cd325fdf51",
            "be505c85f2fd4345ac5501ce4daf1269",
            "c95f36016bf1454db856de5fa43ec8b8",
            "75a7115ce20c43ee9774849d2c3c28ab",
            "6a1a54abdd004a39b1f3d6f966fe355f",
            "00529e75b7074648b5cfdabc1500a15f",
            "e0587be7ce01406c8f4aa53257cf0af0",
            "991954b00b6f4fd3a092bb02650f99d5",
            "80c1fdf61df1489dbdc1240b0be64b73",
            "f826ca15299f468494a93efcfcda5874",
            "e73c76c3c28a46f69764ef4f14d027f4"
          ]
        },
        "id": "JckAAmXbioom",
        "outputId": "76e4a928-02d7-4722-ba5f-805fcf45abda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device set to: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "abaca42bd62f4114935fd710c8574e0d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78b88e69762244f788ee522ab2600949"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "65ed2ae6d16649d48dc074024bf6c76e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "335c909cc5df43738a7cb009bfed2925"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b35a198e20bc42f1bb82d9f2f4bd5a83"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "211ce06e26b949628def5aaa808ebde0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4cf46a88dc9544759366c7cd325fdf51"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the difference between attention and self-attention?\n",
            "Answer: Self-attention, sometimes called intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9DUJAoGUlbfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "81Tiwwb1lbdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### شغال"
      ],
      "metadata": {
        "id": "ThJ96ooml2Bn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# اختيار الجهاز تلقائيًا (CUDA إن وُجد، وإلا CPU)\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "print(\"Using device:\", \"cuda\" if device == 0 else \"cpu\")\n",
        "\n",
        "# تحميل نموذج التضمين\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# تحميل نموذج الإجابة (Flan-T5 base مناسب للفهم والتعليمات)\n",
        "qa_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\", device=device)\n",
        "\n",
        "# قراءة النص الكامل من الملف\n",
        "with open(\"output.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    full_text = f.read()\n",
        "\n",
        "# تقسيم النص إلى مقاطع باستخدام RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=50,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \" \"]\n",
        ")\n",
        "chunks = text_splitter.split_text(full_text)\n",
        "\n",
        "# تحويل المقاطع إلى تمثيلات عددية (embeddings)\n",
        "chunk_embeddings = embedding_model.encode(chunks, convert_to_tensor=True)\n",
        "\n",
        "# دالة الإجابة على الأسئلة\n",
        "def answer_question(question, top_k=3):\n",
        "    # تضمين السؤال\n",
        "    question_embedding = embedding_model.encode(question, convert_to_tensor=True)\n",
        "\n",
        "    # حساب التشابه بين السؤال وكل المقاطع\n",
        "    similarities = util.pytorch_cos_sim(question_embedding, chunk_embeddings)[0]\n",
        "\n",
        "    # اختيار أفضل k مقاطع\n",
        "    top_indices = torch.topk(similarities, k=top_k).indices.tolist()\n",
        "    combined_text = \"\\n\\n\".join([chunks[i] for i in top_indices])\n",
        "\n",
        "    # موجه مطور (prompt) للحصول على إجابة تحليلية\n",
        "    prompt = (\n",
        "        f\"You are an expert in machine learning.\\n\\n\"\n",
        "        f\"Based on the following text, compare and contrast attention and self-attention clearly and analytically.\\n\\n\"\n",
        "        f\"Text:\\n{combined_text}\\n\\n\"\n",
        "        f\"Question: What is the difference between attention and self-attention?\\n\\n\"\n",
        "        f\"Answer:\"\n",
        "    )\n",
        "\n",
        "    # توليد الإجابة\n",
        "    response = qa_pipeline(prompt, max_new_tokens=300, do_sample=False)[0]['generated_text']\n",
        "    return response.strip()\n",
        "\n",
        "# مثال على الاستخدام\n",
        "question = \"What is the difference between attention and self-attention?\"\n",
        "print(\"Question:\", question)\n",
        "print(\"Answer:\", answer_question(question))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUVm9tt8lbYu",
        "outputId": "48c153d5-3bfa-4c61-c741-4bb23944c054"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the difference between attention and self-attention?\n",
            "Answer: Self-attention, sometimes called intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4DlPl7oTlxBV"
      }
    }
  ]
}